{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usada para pre proceso de los datos\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para selección de features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dividir el data en conjunto de entranamiento y testeo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA para reducir dimensionalidad\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medidas de performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficos\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE para balancear los datos\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción, split de datos y detección de desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se abre el archivo\n",
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra el archivos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Se revisa el tipo de datos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa cuántas filas y columnas tiene el dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra una descripción estadística de los datos\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisan las columnas del dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa si es que hay datos nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se indican las variables independientes y la dependiente\n",
    "X_data = data.iloc[:,0:30]\n",
    "y_data = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escala la data para que los datos esten dentro de un mismo rango\n",
    "# Esto se realiza debido a que los datos no presentan una uniformidad en cuanto a su rango\n",
    "# y además porque estaré aplicando PCA ya que son muchas columnas y pueden meter mucho ruido al modelo\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_standard_scaled_df = standard_scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99658302, -0.69424232, -0.04407492, ...,  0.33089162,\n",
       "        -0.06378115,  0.24496426],\n",
       "       [-1.99658302,  0.60849633,  0.16117592, ..., -0.02225568,\n",
       "         0.04460752, -0.34247454],\n",
       "       [-1.99656197, -0.69350046, -0.81157783, ..., -0.13713686,\n",
       "        -0.18102083,  1.16068593],\n",
       "       ...,\n",
       "       [ 1.6419735 ,  0.98002374, -0.18243372, ...,  0.01103672,\n",
       "        -0.0804672 , -0.0818393 ],\n",
       "       [ 1.6419735 , -0.12275539,  0.32125034, ...,  0.26960398,\n",
       "         0.31668678, -0.31324853],\n",
       "       [ 1.64205773, -0.27233093, -0.11489898, ..., -0.00598394,\n",
       "         0.04134999,  0.51435531]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se imprime el df escalado obtenido.\n",
    "X_standard_scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orden y creando el df escalado\n",
    "X_standard_scaled_df = pd.DataFrame(data=X_standard_scaled_df[:,:], columns=['Time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.193679  0.082637  0.331128  ...  0.326118 -0.024923  0.382854 -0.176911   \n",
       "1 -0.063700  0.071253 -0.232494  ... -0.089611 -0.307377 -0.880077  0.162201   \n",
       "2  0.639776  0.207373 -1.378675  ...  0.680975  0.337632  1.063358  1.456320   \n",
       "3  0.192071  0.316018 -1.262503  ... -0.269855 -0.147443  0.007267 -0.304777   \n",
       "4  0.479302 -0.226510  0.744326  ...  0.529939 -0.012839  1.100011 -0.220123   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando el df escaldo\n",
    "X_standard_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que son muchas las columnas y se quiere evitar un exceso de correlaciones es que se opta por\n",
    "# hacer una reducción a las 10 columnas que contengan la mayor varianza de la información\n",
    "pca = PCA(10)\n",
    "\n",
    "pca_selected = pca.fit_transform(X_standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 10)\n"
     ]
    }
   ],
   "source": [
    "# Se comprueba que efectivamente haya reducida solo el numero de columnas\n",
    "print(pca_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea al df\n",
    "pca_selected_df = pd.DataFrame(data=pca_selected[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339744</td>\n",
       "      <td>-2.520156</td>\n",
       "      <td>-0.375307</td>\n",
       "      <td>0.380319</td>\n",
       "      <td>-0.166673</td>\n",
       "      <td>0.098423</td>\n",
       "      <td>0.326416</td>\n",
       "      <td>-0.330437</td>\n",
       "      <td>-0.130874</td>\n",
       "      <td>-0.024067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.391751</td>\n",
       "      <td>-2.135330</td>\n",
       "      <td>-0.509436</td>\n",
       "      <td>-0.371970</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.798872</td>\n",
       "      <td>-0.346844</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>-0.134970</td>\n",
       "      <td>0.537230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.822123</td>\n",
       "      <td>-2.657653</td>\n",
       "      <td>0.158174</td>\n",
       "      <td>0.719508</td>\n",
       "      <td>-0.129938</td>\n",
       "      <td>0.901480</td>\n",
       "      <td>-1.217996</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.489825</td>\n",
       "      <td>-1.667414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347751</td>\n",
       "      <td>-1.800337</td>\n",
       "      <td>0.559366</td>\n",
       "      <td>1.681905</td>\n",
       "      <td>-0.155993</td>\n",
       "      <td>0.109155</td>\n",
       "      <td>0.732799</td>\n",
       "      <td>-0.117564</td>\n",
       "      <td>1.245516</td>\n",
       "      <td>-1.109886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.057478</td>\n",
       "      <td>-1.508531</td>\n",
       "      <td>1.890424</td>\n",
       "      <td>-0.031308</td>\n",
       "      <td>0.480970</td>\n",
       "      <td>-0.682292</td>\n",
       "      <td>0.361249</td>\n",
       "      <td>0.105046</td>\n",
       "      <td>0.343712</td>\n",
       "      <td>-0.009429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.339744 -2.520156 -0.375307  0.380319 -0.166673  0.098423  0.326416   \n",
       "1 -0.391751 -2.135330 -0.509436 -0.371970  0.312400  0.798872 -0.346844   \n",
       "2  1.822123 -2.657653  0.158174  0.719508 -0.129938  0.901480 -1.217996   \n",
       "3  0.347751 -1.800337  0.559366  1.681905 -0.155993  0.109155  0.732799   \n",
       "4 -0.057478 -1.508531  1.890424 -0.031308  0.480970 -0.682292  0.361249   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.330437 -0.130874 -0.024067  \n",
       "1  0.184799 -0.134970  0.537230  \n",
       "2  0.611526  0.489825 -1.667414  \n",
       "3 -0.117564  1.245516 -1.109886  \n",
       "4  0.105046  0.343712 -0.009429  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se imprimre el df\n",
    "pca_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df dinal para trabajar\n",
    "ready_data = pca_selected_df.join(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa la cantidad de 1 y 0 para determinar el balance del dataset\n",
    "# Notamos su desbalance\n",
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casi el 100% de los datos están etiquetados como categoría 1\n",
    "data.Class.value_counts('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráficamente mostrando el desbalance\n",
    "sns.countplot(x=\"Class\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df que contiene la clase 0\n",
    "data_class_0 = ready_data[ready_data['Class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 11)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión del dataset de clase 0\n",
    "data_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df que contiene la clase 1\n",
    "data_class_1 = ready_data[ready_data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 11)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión del dataset de clase 1\n",
    "data_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339744</td>\n",
       "      <td>-2.520156</td>\n",
       "      <td>-0.375307</td>\n",
       "      <td>0.380319</td>\n",
       "      <td>-0.166673</td>\n",
       "      <td>0.098423</td>\n",
       "      <td>0.326416</td>\n",
       "      <td>-0.330437</td>\n",
       "      <td>-0.130874</td>\n",
       "      <td>-0.024067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.391751</td>\n",
       "      <td>-2.135330</td>\n",
       "      <td>-0.509436</td>\n",
       "      <td>-0.371970</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.798872</td>\n",
       "      <td>-0.346844</td>\n",
       "      <td>0.184799</td>\n",
       "      <td>-0.134970</td>\n",
       "      <td>0.537230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.822123</td>\n",
       "      <td>-2.657653</td>\n",
       "      <td>0.158174</td>\n",
       "      <td>0.719508</td>\n",
       "      <td>-0.129938</td>\n",
       "      <td>0.901480</td>\n",
       "      <td>-1.217996</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.489825</td>\n",
       "      <td>-1.667414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.347751</td>\n",
       "      <td>-1.800337</td>\n",
       "      <td>0.559366</td>\n",
       "      <td>1.681905</td>\n",
       "      <td>-0.155993</td>\n",
       "      <td>0.109155</td>\n",
       "      <td>0.732799</td>\n",
       "      <td>-0.117564</td>\n",
       "      <td>1.245516</td>\n",
       "      <td>-1.109886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.057478</td>\n",
       "      <td>-1.508531</td>\n",
       "      <td>1.890424</td>\n",
       "      <td>-0.031308</td>\n",
       "      <td>0.480970</td>\n",
       "      <td>-0.682292</td>\n",
       "      <td>0.361249</td>\n",
       "      <td>0.105046</td>\n",
       "      <td>0.343712</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.339744 -2.520156 -0.375307  0.380319 -0.166673  0.098423  0.326416   \n",
       "1 -0.391751 -2.135330 -0.509436 -0.371970  0.312400  0.798872 -0.346844   \n",
       "2  1.822123 -2.657653  0.158174  0.719508 -0.129938  0.901480 -1.217996   \n",
       "3  0.347751 -1.800337  0.559366  1.681905 -0.155993  0.109155  0.732799   \n",
       "4 -0.057478 -1.508531  1.890424 -0.031308  0.480970 -0.682292  0.361249   \n",
       "\n",
       "          7         8         9  Class  \n",
       "0 -0.330437 -0.130874 -0.024067      0  \n",
       "1  0.184799 -0.134970  0.537230      0  \n",
       "2  0.611526  0.489825 -1.667414      0  \n",
       "3 -0.117564  1.245516 -1.109886      0  \n",
       "4  0.105046  0.343712 -0.009429      0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando el dataset de la clase 0\n",
    "data_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-0.674082</td>\n",
       "      <td>-2.243075</td>\n",
       "      <td>-0.507349</td>\n",
       "      <td>2.618589</td>\n",
       "      <td>-0.518731</td>\n",
       "      <td>-1.226776</td>\n",
       "      <td>-4.738782</td>\n",
       "      <td>1.684324</td>\n",
       "      <td>-1.252510</td>\n",
       "      <td>0.507747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2.517006</td>\n",
       "      <td>-1.825401</td>\n",
       "      <td>0.674458</td>\n",
       "      <td>-1.180975</td>\n",
       "      <td>-0.578167</td>\n",
       "      <td>-1.059401</td>\n",
       "      <td>-0.978058</td>\n",
       "      <td>-0.416277</td>\n",
       "      <td>-0.316794</td>\n",
       "      <td>1.373192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.553980</td>\n",
       "      <td>-2.581654</td>\n",
       "      <td>2.380875</td>\n",
       "      <td>2.030844</td>\n",
       "      <td>-3.454029</td>\n",
       "      <td>0.627265</td>\n",
       "      <td>-3.900063</td>\n",
       "      <td>2.788883</td>\n",
       "      <td>0.526206</td>\n",
       "      <td>-0.638493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-0.875537</td>\n",
       "      <td>-2.673151</td>\n",
       "      <td>5.202067</td>\n",
       "      <td>5.393460</td>\n",
       "      <td>-7.239528</td>\n",
       "      <td>-2.734524</td>\n",
       "      <td>-9.035265</td>\n",
       "      <td>4.303462</td>\n",
       "      <td>-0.507710</td>\n",
       "      <td>-1.870354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>-0.311123</td>\n",
       "      <td>-1.505374</td>\n",
       "      <td>0.630554</td>\n",
       "      <td>-1.943062</td>\n",
       "      <td>-0.135009</td>\n",
       "      <td>1.848210</td>\n",
       "      <td>-1.177561</td>\n",
       "      <td>-1.812485</td>\n",
       "      <td>-2.771255</td>\n",
       "      <td>4.165777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "541  -0.674082 -2.243075 -0.507349  2.618589 -0.518731 -1.226776 -4.738782   \n",
       "623   2.517006 -1.825401  0.674458 -1.180975 -0.578167 -1.059401 -0.978058   \n",
       "4920  0.553980 -2.581654  2.380875  2.030844 -3.454029  0.627265 -3.900063   \n",
       "6108 -0.875537 -2.673151  5.202067  5.393460 -7.239528 -2.734524 -9.035265   \n",
       "6329 -0.311123 -1.505374  0.630554 -1.943062 -0.135009  1.848210 -1.177561   \n",
       "\n",
       "             7         8         9  Class  \n",
       "541   1.684324 -1.252510  0.507747      1  \n",
       "623  -0.416277 -0.316794  1.373192      1  \n",
       "4920  2.788883  0.526206 -0.638493      1  \n",
       "6108  4.303462 -0.507710 -1.870354      1  \n",
       "6329 -1.812485 -2.771255  4.165777      1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Motrando el dataset de la clase 1\n",
    "data_class_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que que se nota que el dataset está desbalanceado, \n",
    "# me preocuparé de balancearlo\n",
    "\n",
    "#Columnas independientes\n",
    "X_0 = data_class_0.iloc[:,0:-1]\n",
    "\n",
    "#Columna dependiente u objetivo\n",
    "y_0 = data_class_0.iloc[:,-1] \n",
    "\n",
    "#Columnas independientes\n",
    "X_1 = data_class_1.iloc[:,0:-1]\n",
    "\n",
    "#Columna dependiente u objetivo\n",
    "y_1 = data_class_1.iloc[:,-1]\n",
    "\n",
    "# Haciendo un split de los datos dejando un 20% para testeo y un 80% para entraniento del modelo\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.20, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateno los conjuntos de entramiento y testeo, tanto para las variables\n",
    "# dependientes como independientes\n",
    "X_train = pd.concat([X_train_0, X_train_1])\n",
    "y_train = pd.concat([y_train_0, y_train_1])\n",
    "X_test = pd.concat([X_test_0 , X_test_1])\n",
    "y_test = pd.concat([y_test_0 , y_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 10)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "Se aplica SMOTE como método de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión original de dataset Counter({0: 227452, 1: 393})\n"
     ]
    }
   ],
   "source": [
    "print('Dimensión original de dataset %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión luego de aplicado el SMOTE Counter({0: 227452, 1: 227452})\n"
     ]
    }
   ],
   "source": [
    "# Aplicando SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Dimensión luego de aplicado el SMOTE %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se llama a la función de sklear con el solver lbgfs\n",
    "logisticRegr = LogisticRegression(solver='lbfgs', max_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el fit creando el modelo\n",
    "logit_model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el objeto para guardar los resultados pronosticados\n",
    "# para el 20% seleccionado para testeo\n",
    "logit_predict = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56857,     6],\n",
       "       [   50,    49]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "# Noto que son pocos los errores que comete FN=52 y FP=5\n",
    "confusion_matrix(y_test, logit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990168884519505"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo el accuracy\n",
    "accuracy_score(y_test, logit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.89      0.49      0.64        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.75      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el reporte de clasificación para tener más información\n",
    "# Noto que el recall y f1 de la clase 1 es bastante bajo y esto se debe\n",
    "# principalmente a la falta de información de este tipo de casos. \n",
    "# Por lo tanto el modelo es muy exacto detectando 0 y no así detectando 1\n",
    "# por lo que la medida accuracy no es tan recomendable para este tipo de \n",
    "# ejercicios y si lo podría ser el f1 que reune una mayor cantidad de información\n",
    "print(classification_report(y_test, logit_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver newton-cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se llama a la función de sklear con el solver lbgfs\n",
    "logisticRegr2 = LogisticRegression(solver='newton-cg', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el fit creando el modelo\n",
    "logit_model = logisticRegr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el objeto para guardar los resultados pronosticados\n",
    "# para el 20% seleccionado para testeo\n",
    "logit_predict2 = logisticRegr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56857,     6],\n",
       "       [   50,    49]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "# Noto que son pocos los errores que comete FN=52 y FP=5\n",
    "confusion_matrix(y_test, logit_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990168884519505"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo el accuracy\n",
    "accuracy_score(y_test, logit_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.89      0.49      0.64        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.75      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el reporte de clasificación para tener más información\n",
    "# Noto que el recall y f1 de la clase 1 es bastante bajo y esto se debe\n",
    "# principalmente a la falta de información de este tipo de casos. \n",
    "# Por lo tanto el modelo es muy exacto detectando 0 y no así detectando 1\n",
    "# por lo que la medida accuracy no es tan recomendable para este tipo de \n",
    "# ejercicios y si lo podría ser el f1 que reune una mayor cantidad de información\n",
    "print(classification_report(y_test, logit_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "No hay mayor diferencia en los resultados ocupando distintos solvers y distintas iteraciones, aunque en temas de cálculo es más rápido lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales densas - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos Keras\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa la red neuronal\n",
    "classifier = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la capa input y la primera capa oculta\n",
    "classifier.add(\n",
    "    keras.layers.Dense(units =10 , kernel_initializer = 'uniform', activation = 'relu', input_dim =10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la capa de salida\n",
    "classifier.add(\n",
    "    keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando la red neuronal\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03265281,  1.65867771, -0.55027124, ..., -0.7917451 ,\n",
       "        -0.56034848, -0.16145618],\n",
       "       [-0.42155737, -1.01031403, -0.3751823 , ...,  0.42543499,\n",
       "        -0.24100832,  0.6565153 ],\n",
       "       [-0.29680497, -1.00012689, -1.0746322 , ...,  0.40999665,\n",
       "        -0.08039517,  0.39698831],\n",
       "       ...,\n",
       "       [-0.6661279 , -0.83154664,  3.79699028, ...,  5.22262285,\n",
       "        -4.62747224, -1.96900537],\n",
       "       [-0.49926199,  1.70478494,  0.36688646, ...,  1.69832468,\n",
       "        -1.59475518, -2.43444679],\n",
       "       [-0.26219737, -0.97748252,  1.09320139, ..., -1.25950104,\n",
       "        -1.19713424, -0.1993216 ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reusmen del clasificador\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1781/1781 [==============================] - 1s 649us/step - loss: 0.2263 - accuracy: 0.9982\n",
      "Epoch 2/5\n",
      "1781/1781 [==============================] - 1s 629us/step - loss: 0.0069 - accuracy: 0.9983\n",
      "Epoch 3/5\n",
      "1781/1781 [==============================] - 1s 626us/step - loss: 0.0059 - accuracy: 0.9982\n",
      "Epoch 4/5\n",
      "1781/1781 [==============================] - 1s 628us/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 5/5\n",
      "1781/1781 [==============================] - 1s 629us/step - loss: 0.0049 - accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "# Haciendo fit a la red neuronal al conjunto de entraniento\n",
    "model = classifier.fit(X_train.values, y_train.values, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 469us/step - loss: 0.0049 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00492074666544795, 0.998981773853302]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo los resultados en el conjunto de testeo\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "score = classifier.evaluate(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.87      0.48      0.62        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.74      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos notar que el f1 score es mejor que el de regresión logística pero muy poco\n",
    "# Por lo que no creo que se justique tal utilización de recursos si el resultado es similar\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: ROC AUC=0.500\n",
      "ROC AUC: ROC AUC=0.939\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Genero una predicción de no fraude (clase mayoritaria)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# Predicciones\n",
    "lr_probs = classifier.predict(X_test)\n",
    "\n",
    "# Mantengo las probabilidades para la salida positiva solamente\n",
    "lr_probs = lr_probs[:, 0]\n",
    "\n",
    "# Calculo los score\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# Resumen\n",
    "print('No Fraude: ROC AUC=%.3f' % (ns_auc))\n",
    "print('ROC AUC: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# Curva ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# graficando\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Fraud')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC AUC')\n",
    "pyplot.xlabel('Falso Positivo')\n",
    "pyplot.ylabel('Verdadero Positivo')\n",
    "plt.title('Exactitud de la detección de fraude')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambiando el número de capas y neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando\n",
    "classifier2 = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input y primera capa\n",
    "classifier2.add(keras.layers.Dense(units = 100 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda capa\n",
    "classifier2.add(keras.layers.Dense(units = 60 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera capa\n",
    "classifier2.add(keras.layers.Dense(units = 40 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuarta capa\n",
    "classifier2.add(keras.layers.Dense(units = 25 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quinta capa\n",
    "classifier2.add(keras.layers.Dense(units = 15 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sexta capa\n",
    "classifier2.add(keras.layers.Dense(units = 5 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Septima capa\n",
    "classifier2.add(keras.layers.Dense(units = 3 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Octava capa\n",
    "classifier2.add(keras.layers.Dense(units = 2 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "classifier2.add(keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando\n",
    "classifier2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 11,124\n",
      "Trainable params: 11,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Resumen\n",
    "classifier2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1781/1781 [==============================] - 3s 1ms/step - loss: 0.1913 - accuracy: 0.9983\n",
      "Epoch 2/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 3/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "Epoch 4/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 5/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# Hago fit al conjunto de entrenamiento\n",
    "model2 = classifier2.fit(X_train.values, y_train.values, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 572us/step - loss: 0.0041 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00413789926096797, 0.9993504285812378]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo\n",
    "y_pred2 = classifier2.predict(X_test)\n",
    "y_pred2 = (y_pred2 > 0.5)\n",
    "score2 = classifier2.evaluate(X_test, y_test)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.83      0.79      0.81        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.89      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: ROC AUC=0.500\n",
      "ROC AUC: ROC AUC=0.968\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Genero una predicción de no fraude (clase mayoritaria)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# Predicciones\n",
    "lr_probs = classifier2.predict(X_test)\n",
    "\n",
    "# Mantengo las probabilidades para la salida positiva solamente\n",
    "lr_probs = lr_probs[:, 0]\n",
    "\n",
    "# Calculo los score\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# Resumen\n",
    "print('No Fraude: ROC AUC=%.3f' % (ns_auc))\n",
    "print('ROC AUC: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# Curva ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# graficando\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Fraud')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC AUC')\n",
    "pyplot.xlabel('Falso Positivo')\n",
    "pyplot.ylabel('Verdadero Positivo')\n",
    "plt.title('Exactitud de la detección de fraude')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Se puede notar que una red neuronal de una capa de entrada obtiene practicamente el mismo resultado que una regresión logística en cuanto a su indicar f1 de 0.63, mientras que una red neuronal de 8 capas y con una entrada de 100 neuronas es capaz de aumentar este f1 a un valor de 0.80. Definitivamente un red densa de varias capas entrega un mejor resultado que una regresión logística, sin embargo, dependiendo de su aplicación, el costo computacional puede ser una variable importante, y en ese caso la red neuronal densa de varias capas es bastante más costosa que una regresión logística. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66e8c3d35df53721f8c9353177b5088a6fbd7e676c257dd4e4a19039e83366ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
