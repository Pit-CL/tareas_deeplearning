{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usada para pre proceso de los datos\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para selección de features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dividir el data en conjunto de entranamiento y testeo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA para reducir dimensionalidad\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medidas de performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficos\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE para balancear los datos\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción, split de datos y detección de desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se abre el archivo\n",
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra el archivos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Se revisa el tipo de datos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa cuántas filas y columnas tiene el dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra una descripción estadística de los datos\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisan las columnas del dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa si es que hay datos nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se indican las variables independientes y la dependiente\n",
    "X_data = data.iloc[:,0:30]\n",
    "y_data = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escala la data para que los datos esten dentro de un mismo rango\n",
    "# Esto se realiza debido a que los datos no presentan una uniformidad en cuanto a su rango\n",
    "# y además porque estaré aplicando PCA ya que son muchas columnas y pueden meter mucho ruido al modelo\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_standard_scaled_df = standard_scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99658302, -0.69424232, -0.04407492, ...,  0.33089162,\n",
       "        -0.06378115,  0.24496426],\n",
       "       [-1.99658302,  0.60849633,  0.16117592, ..., -0.02225568,\n",
       "         0.04460752, -0.34247454],\n",
       "       [-1.99656197, -0.69350046, -0.81157783, ..., -0.13713686,\n",
       "        -0.18102083,  1.16068593],\n",
       "       ...,\n",
       "       [ 1.6419735 ,  0.98002374, -0.18243372, ...,  0.01103672,\n",
       "        -0.0804672 , -0.0818393 ],\n",
       "       [ 1.6419735 , -0.12275539,  0.32125034, ...,  0.26960398,\n",
       "         0.31668678, -0.31324853],\n",
       "       [ 1.64205773, -0.27233093, -0.11489898, ..., -0.00598394,\n",
       "         0.04134999,  0.51435531]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se imprime el df escalado obtenido.\n",
    "X_standard_scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orden y creando el df escalado\n",
    "X_standard_scaled_df = pd.DataFrame(data=X_standard_scaled_df[:,:], columns=['Time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.193679  0.082637  0.331128  ...  0.326118 -0.024923  0.382854 -0.176911   \n",
       "1 -0.063700  0.071253 -0.232494  ... -0.089611 -0.307377 -0.880077  0.162201   \n",
       "2  0.639776  0.207373 -1.378675  ...  0.680975  0.337632  1.063358  1.456320   \n",
       "3  0.192071  0.316018 -1.262503  ... -0.269855 -0.147443  0.007267 -0.304777   \n",
       "4  0.479302 -0.226510  0.744326  ...  0.529939 -0.012839  1.100011 -0.220123   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando el df escaldo\n",
    "X_standard_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que son muchas las columnas y se quiere evitar un exceso de correlaciones es que se opta por\n",
    "# hacer una reducción a las 10 columnas que contengan la mayor varianza de la información\n",
    "pca = PCA(10)\n",
    "\n",
    "pca_selected = pca.fit_transform(X_standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 10)\n"
     ]
    }
   ],
   "source": [
    "# Se comprueba que efectivamente haya reducida solo el numero de columnas\n",
    "print(pca_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea al df\n",
    "pca_selected_df = pd.DataFrame(data=pca_selected[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467086</td>\n",
       "      <td>-2.514264</td>\n",
       "      <td>0.680702</td>\n",
       "      <td>0.557031</td>\n",
       "      <td>0.886159</td>\n",
       "      <td>-0.390670</td>\n",
       "      <td>-0.307698</td>\n",
       "      <td>0.557548</td>\n",
       "      <td>-0.867594</td>\n",
       "      <td>-0.542188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.418486</td>\n",
       "      <td>-2.107611</td>\n",
       "      <td>-0.128977</td>\n",
       "      <td>0.502337</td>\n",
       "      <td>-0.396307</td>\n",
       "      <td>0.563564</td>\n",
       "      <td>0.433359</td>\n",
       "      <td>-0.896725</td>\n",
       "      <td>0.501146</td>\n",
       "      <td>0.473858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.908116</td>\n",
       "      <td>-2.557951</td>\n",
       "      <td>1.961779</td>\n",
       "      <td>0.655338</td>\n",
       "      <td>-0.698543</td>\n",
       "      <td>-0.662131</td>\n",
       "      <td>0.597104</td>\n",
       "      <td>-1.624214</td>\n",
       "      <td>-1.378024</td>\n",
       "      <td>-3.052956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316457</td>\n",
       "      <td>-1.772803</td>\n",
       "      <td>1.545448</td>\n",
       "      <td>0.551811</td>\n",
       "      <td>-1.403620</td>\n",
       "      <td>-2.012082</td>\n",
       "      <td>0.096556</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>-0.578858</td>\n",
       "      <td>-0.792580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007381</td>\n",
       "      <td>-1.514989</td>\n",
       "      <td>-1.398125</td>\n",
       "      <td>0.938197</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>-0.518773</td>\n",
       "      <td>0.326192</td>\n",
       "      <td>0.177108</td>\n",
       "      <td>-1.232140</td>\n",
       "      <td>0.054105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.467086 -2.514264  0.680702  0.557031  0.886159 -0.390670 -0.307698   \n",
       "1 -0.418486 -2.107611 -0.128977  0.502337 -0.396307  0.563564  0.433359   \n",
       "2  1.908116 -2.557951  1.961779  0.655338 -0.698543 -0.662131  0.597104   \n",
       "3  0.316457 -1.772803  1.545448  0.551811 -1.403620 -2.012082  0.096556   \n",
       "4  0.007381 -1.514989 -1.398125  0.938197  0.502000 -0.518773  0.326192   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.557548 -0.867594 -0.542188  \n",
       "1 -0.896725  0.501146  0.473858  \n",
       "2 -1.624214 -1.378024 -3.052956  \n",
       "3 -0.556703 -0.578858 -0.792580  \n",
       "4  0.177108 -1.232140  0.054105  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se imprimre el df\n",
    "pca_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df dinal para trabajar\n",
    "ready_data = pca_selected_df.join(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa la cantidad de 1 y 0 para determinar el balance del dataset\n",
    "# Notamos su desbalance\n",
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casi el 100% de los datos están etiquetados como categoría 1\n",
    "data.Class.value_counts('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráficamente mostrando el desbalance\n",
    "sns.countplot(x=\"Class\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df que contiene la clase 0\n",
    "data_class_0 = ready_data[ready_data['Class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión del dataset de clase 0\n",
    "data_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df que contiene la clase 1\n",
    "data_class_1 = ready_data[ready_data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión del dataset de clase 1\n",
    "data_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.467086</td>\n",
       "      <td>-2.514264</td>\n",
       "      <td>0.680702</td>\n",
       "      <td>0.557031</td>\n",
       "      <td>0.886159</td>\n",
       "      <td>-0.390670</td>\n",
       "      <td>-0.307698</td>\n",
       "      <td>0.557548</td>\n",
       "      <td>-0.867594</td>\n",
       "      <td>-0.542188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.418486</td>\n",
       "      <td>-2.107611</td>\n",
       "      <td>-0.128977</td>\n",
       "      <td>0.502337</td>\n",
       "      <td>-0.396307</td>\n",
       "      <td>0.563564</td>\n",
       "      <td>0.433359</td>\n",
       "      <td>-0.896725</td>\n",
       "      <td>0.501146</td>\n",
       "      <td>0.473858</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.908116</td>\n",
       "      <td>-2.557951</td>\n",
       "      <td>1.961779</td>\n",
       "      <td>0.655338</td>\n",
       "      <td>-0.698543</td>\n",
       "      <td>-0.662131</td>\n",
       "      <td>0.597104</td>\n",
       "      <td>-1.624214</td>\n",
       "      <td>-1.378024</td>\n",
       "      <td>-3.052956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.316457</td>\n",
       "      <td>-1.772803</td>\n",
       "      <td>1.545448</td>\n",
       "      <td>0.551811</td>\n",
       "      <td>-1.403620</td>\n",
       "      <td>-2.012082</td>\n",
       "      <td>0.096556</td>\n",
       "      <td>-0.556703</td>\n",
       "      <td>-0.578858</td>\n",
       "      <td>-0.792580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007381</td>\n",
       "      <td>-1.514989</td>\n",
       "      <td>-1.398125</td>\n",
       "      <td>0.938197</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>-0.518773</td>\n",
       "      <td>0.326192</td>\n",
       "      <td>0.177108</td>\n",
       "      <td>-1.232140</td>\n",
       "      <td>0.054105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.467086 -2.514264  0.680702  0.557031  0.886159 -0.390670 -0.307698   \n",
       "1 -0.418486 -2.107611 -0.128977  0.502337 -0.396307  0.563564  0.433359   \n",
       "2  1.908116 -2.557951  1.961779  0.655338 -0.698543 -0.662131  0.597104   \n",
       "3  0.316457 -1.772803  1.545448  0.551811 -1.403620 -2.012082  0.096556   \n",
       "4  0.007381 -1.514989 -1.398125  0.938197  0.502000 -0.518773  0.326192   \n",
       "\n",
       "          7         8         9  Class  \n",
       "0  0.557548 -0.867594 -0.542188      0  \n",
       "1 -0.896725  0.501146  0.473858      0  \n",
       "2 -1.624214 -1.378024 -3.052956      0  \n",
       "3 -0.556703 -0.578858 -0.792580      0  \n",
       "4  0.177108 -1.232140  0.054105      0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando el dataset de la clase 0\n",
    "data_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-0.519567</td>\n",
       "      <td>-2.508555</td>\n",
       "      <td>2.198123</td>\n",
       "      <td>-0.001858</td>\n",
       "      <td>2.367292</td>\n",
       "      <td>-1.431358</td>\n",
       "      <td>5.108406</td>\n",
       "      <td>-1.033753</td>\n",
       "      <td>2.121784</td>\n",
       "      <td>0.783610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2.599639</td>\n",
       "      <td>-1.881339</td>\n",
       "      <td>-0.514992</td>\n",
       "      <td>0.188516</td>\n",
       "      <td>1.413284</td>\n",
       "      <td>-2.390977</td>\n",
       "      <td>-1.047482</td>\n",
       "      <td>-0.619123</td>\n",
       "      <td>-2.478342</td>\n",
       "      <td>-1.338321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.876778</td>\n",
       "      <td>-2.706077</td>\n",
       "      <td>0.072599</td>\n",
       "      <td>0.108673</td>\n",
       "      <td>0.051955</td>\n",
       "      <td>0.221220</td>\n",
       "      <td>5.725148</td>\n",
       "      <td>-1.224765</td>\n",
       "      <td>1.880414</td>\n",
       "      <td>0.645711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-0.127540</td>\n",
       "      <td>-3.146523</td>\n",
       "      <td>1.187415</td>\n",
       "      <td>1.955207</td>\n",
       "      <td>2.678625</td>\n",
       "      <td>-0.864675</td>\n",
       "      <td>15.170156</td>\n",
       "      <td>-3.331751</td>\n",
       "      <td>2.483913</td>\n",
       "      <td>0.952021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>-0.513325</td>\n",
       "      <td>-1.880389</td>\n",
       "      <td>1.019431</td>\n",
       "      <td>-6.332316</td>\n",
       "      <td>2.264611</td>\n",
       "      <td>-1.263248</td>\n",
       "      <td>-0.813482</td>\n",
       "      <td>-3.358304</td>\n",
       "      <td>-1.336191</td>\n",
       "      <td>1.688282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5          6  \\\n",
       "541  -0.519567 -2.508555  2.198123 -0.001858  2.367292 -1.431358   5.108406   \n",
       "623   2.599639 -1.881339 -0.514992  0.188516  1.413284 -2.390977  -1.047482   \n",
       "4920  0.876778 -2.706077  0.072599  0.108673  0.051955  0.221220   5.725148   \n",
       "6108 -0.127540 -3.146523  1.187415  1.955207  2.678625 -0.864675  15.170156   \n",
       "6329 -0.513325 -1.880389  1.019431 -6.332316  2.264611 -1.263248  -0.813482   \n",
       "\n",
       "             7         8         9  Class  \n",
       "541  -1.033753  2.121784  0.783610      1  \n",
       "623  -0.619123 -2.478342 -1.338321      1  \n",
       "4920 -1.224765  1.880414  0.645711      1  \n",
       "6108 -3.331751  2.483913  0.952021      1  \n",
       "6329 -3.358304 -1.336191  1.688282      1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Motrando el dataset de la clase 1\n",
    "data_class_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que que se nota que el dataset está desbalanceado, \n",
    "# me preocuparé de balancearlo\n",
    "\n",
    "#Columnas independientes\n",
    "X_0 = data_class_0.iloc[:,0:-1]\n",
    "\n",
    "#Columna dependiente u objetivo\n",
    "y_0 = data_class_0.iloc[:,-1] \n",
    "\n",
    "#Columnas independientes\n",
    "X_1 = data_class_1.iloc[:,0:-1]\n",
    "\n",
    "#Columna dependiente u objetivo\n",
    "y_1 = data_class_1.iloc[:,-1]\n",
    "\n",
    "# Haciendo un split de los datos dejando un 20% para testeo y un 80% para entraniento del modelo\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.20, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateno los conjuntos de entramiento y testeo, tanto para las variables\n",
    "# dependientes como independientes\n",
    "X_train = pd.concat([X_train_0, X_train_1])\n",
    "y_train = pd.concat([y_train_0, y_train_1])\n",
    "X_test = pd.concat([X_test_0 , X_test_1])\n",
    "y_test = pd.concat([y_test_0 , y_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "Se aplica SMOTE como método de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión original de dataset Counter({0: 227452, 1: 393})\n"
     ]
    }
   ],
   "source": [
    "print('Dimensión original de dataset %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión luego de aplicado el SMOTE Counter({0: 227452, 1: 227452})\n"
     ]
    }
   ],
   "source": [
    "# Aplicando SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Dimensión luego de aplicado el SMOTE %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se llama a la función de sklear con el solver lbgfs\n",
    "logisticRegr = LogisticRegression(solver='lbfgs', max_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el fit creando el modelo\n",
    "logit_model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el objeto para guardar los resultados pronosticados\n",
    "# para el 20% seleccionado para testeo\n",
    "logit_predict = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56856,     7],\n",
       "       [   53,    46]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "# Noto que son pocos los errores que comete FN=52 y FP=5\n",
    "confusion_matrix(y_test, logit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989466661985184"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo el accuracy\n",
    "accuracy_score(y_test, logit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.87      0.46      0.61        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.73      0.80     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el reporte de clasificación para tener más información\n",
    "# Noto que el recall y f1 de la clase 1 es bastante bajo y esto se debe\n",
    "# principalmente a la falta de información de este tipo de casos. \n",
    "# Por lo tanto el modelo es muy exacto detectando 0 y no así detectando 1\n",
    "# por lo que la medida accuracy no es tan recomendable para este tipo de \n",
    "# ejercicios y si lo podría ser el f1 que reune una mayor cantidad de información\n",
    "print(classification_report(y_test, logit_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver newton-cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se llama a la función de sklear con el solver lbgfs\n",
    "logisticRegr2 = LogisticRegression(solver='newton-cg', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el fit creando el modelo\n",
    "logit_model = logisticRegr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el objeto para guardar los resultados pronosticados\n",
    "# para el 20% seleccionado para testeo\n",
    "logit_predict2 = logisticRegr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56856,     7],\n",
       "       [   53,    46]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "# Noto que son pocos los errores que comete FN=52 y FP=5\n",
    "confusion_matrix(y_test, logit_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989466661985184"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo el accuracy\n",
    "accuracy_score(y_test, logit_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.87      0.46      0.61        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.73      0.80     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el reporte de clasificación para tener más información\n",
    "# Noto que el recall y f1 de la clase 1 es bastante bajo y esto se debe\n",
    "# principalmente a la falta de información de este tipo de casos. \n",
    "# Por lo tanto el modelo es muy exacto detectando 0 y no así detectando 1\n",
    "# por lo que la medida accuracy no es tan recomendable para este tipo de \n",
    "# ejercicios y si lo podría ser el f1 que reune una mayor cantidad de información\n",
    "print(classification_report(y_test, logit_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "No hay mayor diferencia en los resultados ocupando distintos solvers y distintas iteraciones, aunque en temas de cálculo es más rápido lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales densas - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos Keras\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 11:16:25.418900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Se inicializa la red neuronal\n",
    "classifier = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la capa input y la primera capa oculta\n",
    "classifier.add(\n",
    "    keras.layers.Dense(units =10 , kernel_initializer = 'uniform', activation = 'relu', input_dim =10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la capa de salida\n",
    "classifier.add(\n",
    "    keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando la red neuronal\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.02679672e-04,  1.60140363e+00,  1.24926498e+00, ...,\n",
       "         5.47007910e-01, -1.03833474e+00,  4.35865721e-01],\n",
       "       [-4.65510039e-01, -1.05855674e+00,  3.27924850e-01, ...,\n",
       "        -3.97749753e-01,  2.74285649e-01,  2.05949609e-01],\n",
       "       [-3.05744683e-01, -1.01992246e+00,  4.45445239e-01, ...,\n",
       "        -4.92085690e-01,  6.00024923e-01,  1.65814085e-02],\n",
       "       ...,\n",
       "       [-2.28817718e-01, -1.34195567e+00,  2.72241144e+00, ...,\n",
       "        -5.53906628e+00,  5.39326070e+00,  6.75301660e-01],\n",
       "       [-3.44592831e-01,  1.27799486e+00,  1.79193298e+00, ...,\n",
       "        -1.93879361e+00,  1.47808731e+00,  2.09470848e+00],\n",
       "       [-8.76639140e-02, -1.13493721e+00,  5.54949406e-01, ...,\n",
       "         3.81347361e+00,  5.70507833e+00,  5.44563019e-01]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reusmen del clasificador\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 11:16:25.617154: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-09 11:16:25.636910: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2894350000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 2s 949us/step - loss: 0.2319 - accuracy: 0.9982\n",
      "Epoch 2/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "1781/1781 [==============================] - 2s 963us/step - loss: 0.0046 - accuracy: 0.9992\n",
      "Epoch 4/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "1781/1781 [==============================] - 2s 975us/step - loss: 0.0039 - accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "# Haciendo fit a la red neuronal al conjunto de entraniento\n",
    "model = classifier.fit(X_train.values, y_train.values, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 787us/step - loss: 0.0040 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003969484940171242, 0.9991748929023743]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo los resultados en el conjunto de testeo\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "score = classifier.evaluate(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.88      0.61      0.72        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.80      0.86     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos notar que el f1 score es mejor que el de regresión logística pero muy poco\n",
    "# Por lo que no creo que se justique tal utilización de recursos si el resultado es similar\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: ROC AUC=0.500\n",
      "ROC AUC: ROC AUC=0.953\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Genero una predicción de no fraude (clase mayoritaria)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# Predicciones\n",
    "lr_probs = classifier.predict(X_test)\n",
    "\n",
    "# Mantengo las probabilidades para la salida positiva solamente\n",
    "lr_probs = lr_probs[:, 0]\n",
    "\n",
    "# Calculo los score\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# Resumen\n",
    "print('No Fraud: ROC AUC=%.3f' % (ns_auc))\n",
    "print('ROC AUC: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# Curva ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# graficando\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Fraud')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC AUC')\n",
    "pyplot.xlabel('Falso Positivo')\n",
    "pyplot.ylabel('Verdadero Positivo')\n",
    "plt.title('Exactitud de la detección de fraude')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambiando el número de capas y neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando\n",
    "classifier2 = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input y primera capa\n",
    "classifier2.add(keras.layers.Dense(units = 100 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda capa\n",
    "classifier2.add(keras.layers.Dense(units = 60 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera capa\n",
    "classifier2.add(keras.layers.Dense(units = 40 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuarta capa\n",
    "classifier2.add(keras.layers.Dense(units = 25 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quinta capa\n",
    "classifier2.add(keras.layers.Dense(units = 15 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sexta capa\n",
    "classifier2.add(keras.layers.Dense(units = 5 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Septima capa\n",
    "classifier2.add(keras.layers.Dense(units = 3 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Octava capa\n",
    "classifier2.add(keras.layers.Dense(units = 2 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "classifier2.add(keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando\n",
    "classifier2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 11,124\n",
      "Trainable params: 11,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Resumen\n",
    "classifier2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1781/1781 [==============================] - 3s 1ms/step - loss: 0.1827 - accuracy: 0.9984\n",
      "Epoch 2/5\n",
      "1781/1781 [==============================] - 3s 2ms/step - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 3/5\n",
      "1781/1781 [==============================] - 3s 2ms/step - loss: 0.0047 - accuracy: 0.9982\n",
      "Epoch 4/5\n",
      "1781/1781 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9982\n",
      "Epoch 5/5\n",
      "1781/1781 [==============================] - 3s 1ms/step - loss: 0.0040 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "# Hago fit al conjunto de entrenamiento\n",
    "model2 = classifier2.fit(X_train.values, y_train.values, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 747us/step - loss: 0.0037 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003714457619935274, 0.9993153214454651]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo\n",
    "y_pred2 = classifier2.predict(X_test)\n",
    "y_pred2 = (y_pred2 > 0.5)\n",
    "score2 = classifier2.evaluate(X_test, y_test)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.82      0.78      0.80        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.89      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: ROC AUC=0.500\n",
      "ROC AUC: ROC AUC=0.964\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Genero una predicción de no fraude (clase mayoritaria)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# Predicciones\n",
    "lr_probs = classifier2.predict(X_test)\n",
    "\n",
    "# Mantengo las probabilidades para la salida positiva solamente\n",
    "lr_probs = lr_probs[:, 0]\n",
    "\n",
    "# Calculo los score\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# Resumen\n",
    "print('No Fraud: ROC AUC=%.3f' % (ns_auc))\n",
    "print('ROC AUC: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# Curva ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# graficando\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Fraud')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC AUC')\n",
    "pyplot.xlabel('Falso Positivo')\n",
    "pyplot.ylabel('Verdadero Positivo')\n",
    "plt.title('Exactitud de la detección de fraude')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Se puede notar que una red neuronal de una capa de entrada obtiene practicamente el mismo resultado que una regresión logística en cuanto a su indicar f1 de 0.63, mientras que una red neuronal de 8 capas y con una entrada de 100 neuronas es capaz de aumentar este f1 a un valor de 0.80. Definitivamente un red densa de varias capas entrega un mejor resultado que una regresión logística, sin embargo, dependiendo de su aplicación, el costo computacional puede ser una variable importante, y en ese caso la red neuronal densa de varias capas es bastante más costosa que una regresión logística. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66e8c3d35df53721f8c9353177b5088a6fbd7e676c257dd4e4a19039e83366ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
