{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usada para pre proceso de los datos\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usado para selección de features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para dividir el data en conjunto de entranamiento y testeo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA para reducir dimensionalidad\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medidas de performance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficos\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE para balancear los datos\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción, split de datos y detección de desbalanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se abre el archivo\n",
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra el archivos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Se revisa el tipo de datos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa cuántas filas y columnas tiene el dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se muestra una descripción estadística de los datos\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisan las columnas del dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa si es que hay datos nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se indican las variables independientes y la dependiente\n",
    "X_data = data.iloc[:,0:30]\n",
    "y_data = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se escala la data para que los datos esten dentro de un mismo rango\n",
    "# Esto se realiza debido a que los datos no presentan una uniformidad en cuanto a su rango\n",
    "# y además porque estaré aplicando PCA ya que son muchas columnas y pueden meter mucho ruido al modelo\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "X_standard_scaled_df = standard_scaler.fit_transform(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99658302, -0.69424232, -0.04407492, ...,  0.33089162,\n",
       "        -0.06378115,  0.24496426],\n",
       "       [-1.99658302,  0.60849633,  0.16117592, ..., -0.02225568,\n",
       "         0.04460752, -0.34247454],\n",
       "       [-1.99656197, -0.69350046, -0.81157783, ..., -0.13713686,\n",
       "        -0.18102083,  1.16068593],\n",
       "       ...,\n",
       "       [ 1.6419735 ,  0.98002374, -0.18243372, ...,  0.01103672,\n",
       "        -0.0804672 , -0.0818393 ],\n",
       "       [ 1.6419735 , -0.12275539,  0.32125034, ...,  0.26960398,\n",
       "         0.31668678, -0.31324853],\n",
       "       [ 1.64205773, -0.27233093, -0.11489898, ..., -0.00598394,\n",
       "         0.04134999,  0.51435531]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se imprime el df escalado obtenido.\n",
    "X_standard_scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orden y creando el df escalado\n",
    "X_standard_scaled_df = pd.DataFrame(data=X_standard_scaled_df[:,:], columns=['Time','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.326118</td>\n",
       "      <td>-0.024923</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.996583</td>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089611</td>\n",
       "      <td>-0.307377</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680975</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269855</td>\n",
       "      <td>-0.147443</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529939</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n",
       "1 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n",
       "2 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n",
       "3 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n",
       "4 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0  0.193679  0.082637  0.331128  ...  0.326118 -0.024923  0.382854 -0.176911   \n",
       "1 -0.063700  0.071253 -0.232494  ... -0.089611 -0.307377 -0.880077  0.162201   \n",
       "2  0.639776  0.207373 -1.378675  ...  0.680975  0.337632  1.063358  1.456320   \n",
       "3  0.192071  0.316018 -1.262503  ... -0.269855 -0.147443  0.007267 -0.304777   \n",
       "4  0.479302 -0.226510  0.744326  ...  0.529939 -0.012839  1.100011 -0.220123   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.110507  0.246585 -0.392170  0.330892 -0.063781  0.244964  \n",
       "1 -0.561131  0.320694  0.261069 -0.022256  0.044608 -0.342475  \n",
       "2 -1.138092 -0.628537 -0.288447 -0.137137 -0.181021  1.160686  \n",
       "3 -1.941027  1.241904 -0.460217  0.155396  0.186189  0.140534  \n",
       "4  0.233250 -0.395202  1.041611  0.543620  0.651816 -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando el df escaldo\n",
    "X_standard_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que son muchas las columnas y se quiere evitar un exceso de correlaciones es que se opta por\n",
    "# hacer una reducción a las 10 columnas que contengan la mayor varianza de la información\n",
    "pca = PCA(10)\n",
    "\n",
    "pca_selected = pca.fit_transform(X_standard_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 10)\n"
     ]
    }
   ],
   "source": [
    "# Se comprueba que efectivamente haya reducida solo el numero de columnas\n",
    "print(pca_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea al df\n",
    "pca_selected_df = pd.DataFrame(data=pca_selected[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.429327</td>\n",
       "      <td>-2.558748</td>\n",
       "      <td>0.541462</td>\n",
       "      <td>0.445674</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>0.722745</td>\n",
       "      <td>-0.587755</td>\n",
       "      <td>0.199037</td>\n",
       "      <td>0.641719</td>\n",
       "      <td>-0.903754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.395422</td>\n",
       "      <td>-2.064952</td>\n",
       "      <td>-0.360145</td>\n",
       "      <td>-1.245191</td>\n",
       "      <td>0.372056</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>0.587192</td>\n",
       "      <td>-0.048522</td>\n",
       "      <td>-0.314333</td>\n",
       "      <td>-0.323271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.862410</td>\n",
       "      <td>-2.415882</td>\n",
       "      <td>-0.433063</td>\n",
       "      <td>-1.073339</td>\n",
       "      <td>-0.350719</td>\n",
       "      <td>3.067971</td>\n",
       "      <td>-1.654522</td>\n",
       "      <td>-1.709630</td>\n",
       "      <td>1.255708</td>\n",
       "      <td>0.112185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312455</td>\n",
       "      <td>-1.693929</td>\n",
       "      <td>-1.255993</td>\n",
       "      <td>-0.841185</td>\n",
       "      <td>-1.747855</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.335829</td>\n",
       "      <td>0.075009</td>\n",
       "      <td>0.593281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-1.424787</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>1.040655</td>\n",
       "      <td>-0.253045</td>\n",
       "      <td>-0.175155</td>\n",
       "      <td>-0.412396</td>\n",
       "      <td>0.703398</td>\n",
       "      <td>0.989797</td>\n",
       "      <td>-0.726846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.429327 -2.558748  0.541462  0.445674 -0.086266  0.722745 -0.587755   \n",
       "1 -0.395422 -2.064952 -0.360145 -1.245191  0.372056  0.140075  0.587192   \n",
       "2  1.862410 -2.415882 -0.433063 -1.073339 -0.350719  3.067971 -1.654522   \n",
       "3  0.312455 -1.693929 -1.255993 -0.841185 -1.747855  0.005791  0.011842   \n",
       "4 -0.012979 -1.424787  0.549349  1.040655 -0.253045 -0.175155 -0.412396   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.199037  0.641719 -0.903754  \n",
       "1 -0.048522 -0.314333 -0.323271  \n",
       "2 -1.709630  1.255708  0.112185  \n",
       "3  0.335829  0.075009  0.593281  \n",
       "4  0.703398  0.989797 -0.726846  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se imprimre el df\n",
    "pca_selected_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df dinal para trabajar\n",
    "ready_data = pca_selected_df.join(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se revisa la cantidad de 1 y 0 para determinar el balance del dataset\n",
    "# Notamos su desbalance\n",
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casi el 100% de los datos están etiquetados como categoría 1\n",
    "data.Class.value_counts('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafa/miniconda3/envs/deep/lib/python3.9/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráficamente mostrando el desbalance\n",
    "sns.countplot(x=\"Class\", data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df que contiene la clase 0\n",
    "data_class_0 = ready_data[ready_data['Class']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 11)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión del dataset de clase 0\n",
    "data_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df que contiene la clase 1\n",
    "data_class_1 = ready_data[ready_data['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 11)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensión del dataset de clase 1\n",
    "data_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.429327</td>\n",
       "      <td>-2.558748</td>\n",
       "      <td>0.541462</td>\n",
       "      <td>0.445674</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>0.722745</td>\n",
       "      <td>-0.587755</td>\n",
       "      <td>0.199037</td>\n",
       "      <td>0.641719</td>\n",
       "      <td>-0.903754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.395422</td>\n",
       "      <td>-2.064952</td>\n",
       "      <td>-0.360145</td>\n",
       "      <td>-1.245191</td>\n",
       "      <td>0.372056</td>\n",
       "      <td>0.140075</td>\n",
       "      <td>0.587192</td>\n",
       "      <td>-0.048522</td>\n",
       "      <td>-0.314333</td>\n",
       "      <td>-0.323271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.862410</td>\n",
       "      <td>-2.415882</td>\n",
       "      <td>-0.433063</td>\n",
       "      <td>-1.073339</td>\n",
       "      <td>-0.350719</td>\n",
       "      <td>3.067971</td>\n",
       "      <td>-1.654522</td>\n",
       "      <td>-1.709630</td>\n",
       "      <td>1.255708</td>\n",
       "      <td>0.112185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.312455</td>\n",
       "      <td>-1.693929</td>\n",
       "      <td>-1.255993</td>\n",
       "      <td>-0.841185</td>\n",
       "      <td>-1.747855</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.335829</td>\n",
       "      <td>0.075009</td>\n",
       "      <td>0.593281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-1.424787</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>1.040655</td>\n",
       "      <td>-0.253045</td>\n",
       "      <td>-0.175155</td>\n",
       "      <td>-0.412396</td>\n",
       "      <td>0.703398</td>\n",
       "      <td>0.989797</td>\n",
       "      <td>-0.726846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.429327 -2.558748  0.541462  0.445674 -0.086266  0.722745 -0.587755   \n",
       "1 -0.395422 -2.064952 -0.360145 -1.245191  0.372056  0.140075  0.587192   \n",
       "2  1.862410 -2.415882 -0.433063 -1.073339 -0.350719  3.067971 -1.654522   \n",
       "3  0.312455 -1.693929 -1.255993 -0.841185 -1.747855  0.005791  0.011842   \n",
       "4 -0.012979 -1.424787  0.549349  1.040655 -0.253045 -0.175155 -0.412396   \n",
       "\n",
       "          7         8         9  Class  \n",
       "0  0.199037  0.641719 -0.903754      0  \n",
       "1 -0.048522 -0.314333 -0.323271      0  \n",
       "2 -1.709630  1.255708  0.112185      0  \n",
       "3  0.335829  0.075009  0.593281      0  \n",
       "4  0.703398  0.989797 -0.726846      0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrando el dataset de la clase 0\n",
    "data_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-0.462716</td>\n",
       "      <td>-2.387369</td>\n",
       "      <td>-2.240275</td>\n",
       "      <td>0.673442</td>\n",
       "      <td>-3.201856</td>\n",
       "      <td>2.364220</td>\n",
       "      <td>2.377637</td>\n",
       "      <td>-2.019630</td>\n",
       "      <td>0.826743</td>\n",
       "      <td>-0.097278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2.599842</td>\n",
       "      <td>-1.611025</td>\n",
       "      <td>-0.383757</td>\n",
       "      <td>0.282205</td>\n",
       "      <td>-0.583363</td>\n",
       "      <td>0.384939</td>\n",
       "      <td>1.027246</td>\n",
       "      <td>-1.810823</td>\n",
       "      <td>0.193466</td>\n",
       "      <td>-2.354425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>0.763366</td>\n",
       "      <td>-2.896775</td>\n",
       "      <td>-2.858039</td>\n",
       "      <td>2.216712</td>\n",
       "      <td>-2.557896</td>\n",
       "      <td>1.771259</td>\n",
       "      <td>1.273949</td>\n",
       "      <td>-0.473348</td>\n",
       "      <td>3.239593</td>\n",
       "      <td>1.226797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-0.219429</td>\n",
       "      <td>-3.464122</td>\n",
       "      <td>-5.626987</td>\n",
       "      <td>6.439302</td>\n",
       "      <td>-7.407667</td>\n",
       "      <td>1.461432</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>-2.387414</td>\n",
       "      <td>6.571089</td>\n",
       "      <td>4.298257</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>-0.413951</td>\n",
       "      <td>-1.053584</td>\n",
       "      <td>-4.374457</td>\n",
       "      <td>0.730334</td>\n",
       "      <td>2.498211</td>\n",
       "      <td>2.455621</td>\n",
       "      <td>-0.176776</td>\n",
       "      <td>-1.834915</td>\n",
       "      <td>0.900485</td>\n",
       "      <td>0.644579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "541  -0.462716 -2.387369 -2.240275  0.673442 -3.201856  2.364220  2.377637   \n",
       "623   2.599842 -1.611025 -0.383757  0.282205 -0.583363  0.384939  1.027246   \n",
       "4920  0.763366 -2.896775 -2.858039  2.216712 -2.557896  1.771259  1.273949   \n",
       "6108 -0.219429 -3.464122 -5.626987  6.439302 -7.407667  1.461432  4.393188   \n",
       "6329 -0.413951 -1.053584 -4.374457  0.730334  2.498211  2.455621 -0.176776   \n",
       "\n",
       "             7         8         9  Class  \n",
       "541  -2.019630  0.826743 -0.097278      1  \n",
       "623  -1.810823  0.193466 -2.354425      1  \n",
       "4920 -0.473348  3.239593  1.226797      1  \n",
       "6108 -2.387414  6.571089  4.298257      1  \n",
       "6329 -1.834915  0.900485  0.644579      1  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Motrando el dataset de la clase 1\n",
    "data_class_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que que se nota que el dataset está desbalanceado, \n",
    "# me preocuparé de balancearlo\n",
    "\n",
    "#Columnas independientes\n",
    "X_0 = data_class_0.iloc[:,0:-1]\n",
    "\n",
    "#Columna dependiente u objetivo\n",
    "y_0 = data_class_0.iloc[:,-1] \n",
    "\n",
    "#Columnas independientes\n",
    "X_1 = data_class_1.iloc[:,0:-1]\n",
    "\n",
    "#Columna dependiente u objetivo\n",
    "y_1 = data_class_1.iloc[:,-1]\n",
    "\n",
    "# Haciendo un split de los datos dejando un 20% para testeo y un 80% para entraniento del modelo\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_0, y_0, test_size=0.20, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateno los conjuntos de entramiento y testeo, tanto para las variables\n",
    "# dependientes como independientes\n",
    "X_train = pd.concat([X_train_0, X_train_1])\n",
    "y_train = pd.concat([y_train_0, y_train_1])\n",
    "X_test = pd.concat([X_test_0 , X_test_1])\n",
    "y_test = pd.concat([y_test_0 , y_test_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962, 10)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56962,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviso que la dimensión sea la correcta\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "\n",
    "Se aplica SMOTE como método de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión original de dataset Counter({0: 227452, 1: 393})\n"
     ]
    }
   ],
   "source": [
    "print('Dimensión original de dataset %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión luego de aplicado el SMOTE Counter({0: 227452, 1: 227452})\n"
     ]
    }
   ],
   "source": [
    "# Aplicando SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print('Dimensión luego de aplicado el SMOTE %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se llama a la función de sklear con el solver lbgfs\n",
    "logisticRegr = LogisticRegression(solver='lbfgs', max_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el fit creando el modelo\n",
    "logit_model = logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el objeto para guardar los resultados pronosticados\n",
    "# para el 20% seleccionado para testeo\n",
    "logit_predict = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56858,     5],\n",
       "       [   52,    47]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "# Noto que son pocos los errores que comete FN=52 y FP=5\n",
    "confusion_matrix(y_test, logit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989993328885924"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo el accuracy\n",
    "accuracy_score(y_test, logit_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.90      0.47      0.62        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.74      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el reporte de clasificación para tener más información\n",
    "# Noto que el recall y f1 de la clase 1 es bastante bajo y esto se debe\n",
    "# principalmente a la falta de información de este tipo de casos. \n",
    "# Por lo tanto el modelo es muy exacto detectando 0 y no así detectando 1\n",
    "# por lo que la medida accuracy no es tan recomendable para este tipo de \n",
    "# ejercicios y si lo podría ser el f1 que reune una mayor cantidad de información\n",
    "print(classification_report(y_test, logit_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver newton-cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se llama a la función de sklear con el solver lbgfs\n",
    "logisticRegr2 = LogisticRegression(solver='newton-cg', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el fit creando el modelo\n",
    "logit_model = logisticRegr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea el objeto para guardar los resultados pronosticados\n",
    "# para el 20% seleccionado para testeo\n",
    "logit_predict2 = logisticRegr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56858,     5],\n",
       "       [   52,    47]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "# Noto que son pocos los errores que comete FN=52 y FP=5\n",
    "confusion_matrix(y_test, logit_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989993328885924"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculo el accuracy\n",
    "accuracy_score(y_test, logit_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.90      0.47      0.62        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.74      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo el reporte de clasificación para tener más información\n",
    "# Noto que el recall y f1 de la clase 1 es bastante bajo y esto se debe\n",
    "# principalmente a la falta de información de este tipo de casos. \n",
    "# Por lo tanto el modelo es muy exacto detectando 0 y no así detectando 1\n",
    "# por lo que la medida accuracy no es tan recomendable para este tipo de \n",
    "# ejercicios y si lo podría ser el f1 que reune una mayor cantidad de información\n",
    "print(classification_report(y_test, logit_predict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "No hay mayor diferencia en los resultados ocupando distintos solvers y distintas iteraciones, aunque en temas de cálculo es más rápido lbfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales densas - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos Keras\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa la red neuronal\n",
    "classifier = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la capa input y la primera capa oculta\n",
    "classifier.add(\n",
    "    keras.layers.Dense(units =10 , kernel_initializer = 'uniform', activation = 'relu', input_dim =10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregando la capa de salida\n",
    "classifier.add(\n",
    "    keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando la red neuronal\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01358778,  1.64340207,  0.53297732, ..., -1.58984887,\n",
       "         1.30325574, -0.18630953],\n",
       "       [-0.415891  , -1.06158463,  0.17234702, ...,  0.72712187,\n",
       "        -0.92542625,  0.59693331],\n",
       "       [-0.27896224, -1.05719938,  0.75231122, ..., -0.06934206,\n",
       "        -0.36308389,  0.47039348],\n",
       "       ...,\n",
       "       [-0.12989899, -1.15115446, -7.42287314, ..., -6.18326178,\n",
       "         2.29689405,  1.33012651],\n",
       "       [-0.27829028,  1.44161565, -2.98166524, ..., -2.1788108 ,\n",
       "         0.41652406,  2.30162566],\n",
       "       [-0.08658629, -1.2705195 , -1.19257137, ...,  2.71171832,\n",
       "         2.05243882, -1.40288614]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reusmen del clasificador\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1781/1781 [==============================] - 1s 651us/step - loss: 0.2377 - accuracy: 0.9961\n",
      "Epoch 2/5\n",
      "1781/1781 [==============================] - 1s 604us/step - loss: 0.0062 - accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "1781/1781 [==============================] - 1s 603us/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 4/5\n",
      "1781/1781 [==============================] - 1s 627us/step - loss: 0.0044 - accuracy: 0.9992\n",
      "Epoch 5/5\n",
      "1781/1781 [==============================] - 1s 637us/step - loss: 0.0036 - accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# Haciendo fit a la red neuronal al conjunto de entraniento\n",
    "model = classifier.fit(X_train.values, y_train.values, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 463us/step - loss: 0.0044 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0043539865873754025, 0.9990344643592834]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo los resultados en el conjunto de testeo\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "score = classifier.evaluate(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.84      0.55      0.66        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.77      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos notar que el f1 score es mejor que el de regresión logística pero muy poco\n",
    "# Por lo que no creo que se justique tal utilización de recursos si el resultado es similar\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: ROC AUC=0.500\n",
      "ROC AUC: ROC AUC=0.945\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+AElEQVR4nO3dd3wUdfrA8c+TRkIINaEHEkLvQqiC2LAgxXYgeiLqT87CKaeeov5U7qfnnZ6KKJbDAmIDD7HA2bCCIiIgvZdAIr3XkPb8/pgJLiEJm7CbzWaf9+sVdqfszDObMM/Md2aer6gqxhhjQldYoAMwxhgTWJYIjDEmxFkiMMaYEGeJwBhjQpwlAmOMCXGWCIwxJsRZIjBeEZEHReQ1Hy5vjIi8XYL5VUSalmI9w0Xkh5J+zt/L8oWificicraIzBeRGj5aT5L7/UeU4rMiIhNFZJ+IzPdFPF6sM01ELiyLdVUUJf7FmrInImlAHSDXY/QkVR3pp/WdC7ytqg3zx6nqEx7Tk4BNQKSq5vgjhmAnIpOADFX9X3+tw/N34rHeROAJoL+q7vPXukugF9AXaKiqRwIdjCmcJYLgMUBVvwp0EKZ8U9V0oE+g4/DQGEgrKgmISIQdTASeNQ0FORF5WUSmeQw/KSJfu6fkNURkpojsck/NZ4pIQ495a7qn7Vvd6R+JSCzwGVBfRA67P/ULNOXMdl/3u9N7FGzqKdicICLJIvK9iBwSkVlA/Gm2668iss2N7aYC0yqJyNMiskVEdojIKyIS4+X3NU5E0kXkoIgsFJHexcxbS0Q+ceedD6QUmN5SRGaJyF4RWSMig93xI4DrgPvc72eGO76+iHzg/j42icidHssKd5t6Nrjf0UL36B4RaeOxnh0i8qA7vuB3PlBEVojIfhH5TkRaeUxLE5F7RWSpiBwQkakiEl3Edoe73+9uEdkIXFZgejURed39/fwmIo+LSHghy7kZeA3o4X4PfxORc0UkQ0TuF5HtwEQv/k5PauopZLuvF5HNIrJHRB4qEEOYiIx2v9c9IvK+iNQsbLtDmSWC4HcP0F6c9uvewM3ADerUDgkDJuIclTUCjgHjPT77FlAZaAPUBsa6R26XAltVtYr7s7XAOs9xX6u703/yIs53gYU4CeAx4IaiZhSRS4B7cZoUmgEF23ufBJoDHYGmQAPgES9iAPjF/VxNN6b/FLVDBF4EMoF6wE3uT36MscAsdxm1gaHASyLSRlUnAO8AT7nfzwARCQNmAEvceC8ARonIxe4i73aX0Q+o6q7rqIjEAV8BnwP13e39umCgItIceA8YBSQAnwIzRCTKY7bBwCVAMtAeGF7Edt8C9AfOAlKBqwtMfxPIcWM5C7gI+J+CC1HV14FbgZ/c7+FRd1JdnO+/MTCC0/+dFklEWgMvA9fjfD+1gIYes9wJXI5zllQf2IfzezWeVNV+yvkPkAYcBvZ7/NziMb0rsBfYDAwtZjkdgX3u+3pAHlCjkPnOxWnf9hw3Bue6AUASoEBEYdMLzoPznzsHiPWY/q7n/AXW9QbwT4/h5u6ymgICHAFSPKb3ADYVsazhwA/FfCf7gA6FjA8HsoGWHuOeyF8WMASYU+Az/wYedd9PAh73mNYN2FJg/geAie77NcCgQuIYCvxaROyev5OHgfc9poUBvwHnevwN/dFj+lPAK0Us9xvgVo/hizx+l3WA40BMgRi/9eb7d/+2soBob/5OPWK/sIjtfgSY4jEt1l3+he7wKuACj+n13N9rRFHrD8Ufu0YQPC7XIq4RqOp89xS+NvB+/ngRqQyMxTkKzL+DJM49jU8E9mrZXFCsj/Mf27OdeLMbQ1HzLywwb74EnLOYhSKSP05wdtynJSL34By91sfZuVWl8GaqBJwdX3oRcTQGuonIfo9xEThnWYVpjNPc5jl/ODDHfZ8IbCjkc0WNL6i+Z3yqmici6ThnH/m2e7w/6n6mqGUVt92RwDaP7z+swPyns0tVM/MHivs7VdXcwhZQVKyqekRE9hSI90MRyfMYl4uT0H4rQcwVmjUNVQAicgdQCdgK3Ocx6R6gBdBNVavye5OO4PznqSki1QtZ5OlK0hY2/QjODjpfXY/324AabnNKvkbFLH8bJycJz3l34zQdtFHV6u5PNVWtcpqYcZvO7sdpIqmhqtWBAzjfR0G7cM5iioojHfjeI4bq6jR/3OZOL/gdpeOctXjOH6eq/Tymp3CqosYXtBVnp5e/reLGXpqdXXHffzrOGUG8x3ZUVdU2JVh+we+muL9TOP3f1olY3aRSq0C8lxb43qNV1ZKAB0sEQc5tG34c+CNOO+l9ItLRnRyHs9Pc714gy2+jRVW34VwUfsm9WBcpIvn/AXcAtUSkWhGr3YXTrNTEY9xi4BwRaeR+7gGPdW0GFgB/E5EoEekFDChms94HhotIa/c/tmfcecCrwFgRqe1+Bw082tqLE4ezc98FRIjIIzhnBKdwj0SnA2NEpLLbFu15XWMm0Ny9UBnp/nTxuEC7g5O/n/nAQfciaYx7QbatiHRxp78GPCYizcTRXkRqueupKyKjxLlIHici3Yr4zi4TkQtEJBJn53ocmOvF91LYsu4UkYbiPIsw2uN72QZ8CTwjIlXdi7EpInImdyoV+XfqWgxc437HBa9ZTAP6i0gv93rI/3Hyfu0V4O8i0hhARBJEZNAZxFohWSIIHjPk97t4DovIh+LckfM28KSqLlHVdcCDwFsiUgl4DojBOYqeh3PB0dP1OO2lq4GdOBcaUdXVOBceN4pzB8pJTQiqehT4O/CjO727qs4CpgJLcZp1ZhZY17U47eR7cf6jTy5qQ1X1Mzf2b4D17qun+93x80TkIM7F1BZFLc/DFzjJby1Oc0cmxTdpjASq4DSpTMK5oJkf4yGctvNrcI7Gt+NcxK7kzvI60Nr9fj5yE8sAnPbvTTi/k9eA/GT7LM4O+EvgoPv5GHc9fd3PbgfWAecVDFRV1+AcDLzgLnsAzi3HWV58LwW9ivNdLQEW4SRET8OAKGAlzjWWaTht76X1HMX/nT6Mc1a0D/gbzvUlAFR1BXCHO26bO0+Gx2fHAZ8AX4rIIXf5hSXSkCbuBRRjjDEhys4IjDEmxFkiMMaYEGeJwBhjQpwlAmOMCXFB90BZfHy8JiUlBToMY4wJKgsXLtytqgmFTQu6RJCUlMSCBQsCHYYxxgQVEdlc1DRrGjLGmBBnicAYY0KcJQJjjAlxlgiMMSbEWSIwxpgQ57dEICJviMhOEVlexHQRkedFZL043ed18lcsxhhjiubP20cn4XQ3V1SVyUtxuiFshlMN8GWsKqAxxpwsfT6kzYGdq+G3BdBqIPT9m09X4bdEoKqzRSSpmFkGAZPVKX86T0Sqi0g9t965McaY9PkwqT+aexxwe+r58Tlnmg+TQSAfKGvAybXgM9xxpyQCERmB08k1jRoV17GVMcYEufwzgE0/QNocNC8boUC3bqs+qTCJoLDuAQvtHEFVJwATAFJTU60DBWNMxbT5J3hzAORl/74zVNCCe8tWA3262kAmggxO7he1IU5PT8YYE3zyj+QzD8L2pdDK7RFz1cdQOR6O7nbGpQ53xn9wC6yfBTWaQEw1Z9qO5ZCXfWKRcuIfV0wN6HRD8Fwj8MInwEgRmYJzkfiAXR8wxgQlty0fty0fgA0Fe1h1x62ZCfszYNcqZ9yxhSem5VRrfNJOWfHIA2GRcO37kNjV5+H7LRGIyHvAuUC8iGTg9FMbCaCqrwCfAv1w+p49Ctzor1iMqXBmPQq/vg1RlSGxu3O0eewA7NsIUXFwZDeEhUNUrDN/THWo2x62LYHMA85wZCxsdXdC1RpBo+6wbBqQB/mt0lFxcNHjsPlHWDUTNBdy3W6Qo6s7s+WvLzoOkvvAxu/hyE5OtPTW7wwj3J3ihPOddUo4VG3w++fOffD3I+UFk2DeSyAC3W5z1p1/5Jx12BnvuS3H9rk7YHGmVW0I8U1PPiI/dsA5SheB1pdD47Od8Z5H6PnrzTzw+3cWGQs7V/2+bUd3O0f325b8Hl/qcOdMwDMJFGfdrEJHKxB2YPOJnb8AhEVApTgn3rPv8ksSgCDsszg1NVWt+qgJabMe/f3OkWARW9d5PbK96Hma9nVe1xe+o/SbM11vST/ff5yT3Ja9D3DStYD3oq7kmrxPCcvLhvAouOETn+38RWShqqYWNi3oylAbEzTS58OkAZCb6RzZxdWHQ1uhbgfoNOzUtmNwjkj3pTntxJWqOUfAeTkgYc4yVE9qQw4axSWAfGWdAHy13vWzOOXel5pNoOddzvvCrhG4ZyHZa75kZVYCB3KjOdasP1cO/Sth2xc6ZxhJvf12BlCQnREY4w/p8+H1voGOovyo39l5zW+KKkz/cc7rzLv8H48v19t/HNRpDW8OdJrNSnAkv3r7QR6YvozHL29Lm/rVSrd+L9kZgTG+MvkK2PgdhIVBmyudcSfa1T2ER5VdTHXbQWxCxblGAIG5RpC/3tJcIwBn53+aI3lVZdrCDFZsPciYgW1oWbcq02/riUhhd9OXHTsjMMZbk6+AjYXcCRJIYZFw46dl1oRgSi9971Ee/HAZc9btpmtSTSbf3JXoyPAyW7+dEZjyY4x/T3/LrzCo1tA31wgiKkHlms6ZgB/vJDG+kZunTP4pjac+X0OYwGOXt+W6ro0ICwvsWYAnSwSm7IRqEijqqN2zSaK4cSao7T2SxbOz1tKtSU3+fkU7GlSPCXRIp7BEEEpCdUfsT+0GF36NICrOjtpDWHZuHh/9+htXdWpIQlwl/vvn3iTWjAn4tYCiWCIIFZYEfE/C4apXnR9jXMsyDvDXaUtYvf0QtatG06d5Ao1qVQ50WMWyROBP/2oOR3YEOgrjDxIOj+4NdBSmHMnMzuW5r9bx6pyN1IqN4t/Xd6ZP84RAh+UVSwT+YknAO2MOBDoCY3zilskLmLNuN9d0SeSBfq2oFhMZ6JC8ZonAF4Lxkf/ywJKACXKHMrOJDA8jOjKcO85ryq19Uji7aXygwyoxSwRnKpiTgO2IjSm1b1fv5KEPl3H5WQ2475KWdG9SK9AhlZolgpIK5h2/J0sCxpTK3iNZPDZzJR/++hvNalfhwtZ1Ah3SGbNEUBJnkgSi4uDBDJ+GY4wpW3PW7WLUlMUcOJbNnRc0447zUqgUUXZPB/uLJQJvje8Ku9eU7rOWBIypEGrHRZMcH8vjV7SlZd2qgQ7HZywReKNESUBgzH5/RmOMKSOqytRf0lmx9SCPXd6WFnXj+M+tPcrtg2GlZYmgMKU++rckYExFsWXPUUZPX8rcDXvo3qQmmdm5REeGV7gkAJYITlWSJNDkfBj2oX/jMcaUqdw8ZeKPm3j6yzVEhIXxxBXtuKZLYrkqEudrlgg8pc+3JGBMiNt7JItxX6/j7JR4Hr+iLfWqlb8icb5miSDf5nkw8WIvZhS4+UsrImZMBZKV4xSJu7qzUyTu0zt707BG+S0S52uWCNLnO7eErvn89PNWqgZ/nGZJwJgKZEn6fu6btpQ1Ow5Rt1o05zRPILFm+S4S52uhnQjS58PrF3NKCeF8Eg43fW47fmMqoGNZuTw7aw2v/7CJ2nHRvDYslXOCpEicr4V2IljyHkUmgSp1YMjblgSMqaBumbyAH9bvZmjXRjzQryVVo4OnSJyvhW4iSJ8PC94oYqJYEjCmAjqYmU2UWyTuz+c35fbzUuiZEnxF4nwtLNABBEzanMLHx9W3i8HGVEBfr9rBRc/OZtzX6wDo1qSWJQFX6J4RHC2kUxG7JdSYCmfP4eP8bcZKPlmylZZ147ikTd1Ah1TuhGYimHwFbPzm5HHRNSwJGFPBzF67i1FTF3MoM5u/XNic285NISoidBtCihJ6iaCwJADQ+Yayj8UY41d1q0XTNKEKj1/RluZ14gIdTrkVWqkxfT6kzS58WnTFqSRoTKjKy1Pe/XkLD324DIDmdeJ4/9YelgROI3TOCNLnw8RLIS/n1GlhkZDUu+xjMsb4TNruI4yevpR5G/fSo0mtE0XizOmFTiJY92XhSSCyMgz72O4SMiZI5eYpb/ywiWdmrSEyLIx/XtmOIV0SQ6Y8hC/4tWlIRC4RkTUisl5ERhcyvZqIzBCRJSKyQkRu9Fswx4romrHrCEsCxgSxvUeyeOGbdfRqmsCsu/twTddGlgRKyG9nBCISDrwI9AUygF9E5BNVXekx2x3ASlUdICIJwBoReUdVs3we0M6VJw9HREO3W6Hv33y+KmOMfx3PyWX6ot8YkproFIm7qzcNqodOkThf82fTUFdgvapuBBCRKcAgwHOPrECcOL+9KsBeoJD2Gx9odiFs/uH34UuehNThflmVMcZ/ft2yj/s/WMraHYdpUD2Gc5on0LBGaBWJ8zV/Ng01ANI9hjPccZ7GA62ArcAy4C5VPaX4j4iMEJEFIrJg165dpYum3R+c18hYaDfYkoAxQeZoVg6PzVzJlS/P5VBmDhOHdwnZInG+5s9EUNg5mhYYvhhYDNQHOgLjReSU+zhVdYKqpqpqakJCKX/xS6Y6r9lHYNn7sGBS6ZZjjAmIEZMX8voPm7iuWyO+/Ms5nNeydqBDqjD8mQgygESP4YY4R/6ebgSmq2M9sAlo6Zdo1s86eXjVx35ZjTHGdw4cyyYzOxeAOy9oxtQR3Xn88nbEhXClUH/wZyL4BWgmIskiEgVcA3xSYJ4twAUAIlIHaAFs9Es0lQo8UFLZik0ZU57NWrmDi8Z+z3NfOUXiuibXpFuTWgGOqmLy28ViVc0RkZHAF0A48IaqrhCRW93prwCPAZNEZBlOU9L9qrrbLwEdKbDYo/5ZjTHmzOw+fJwxn6xg5tJttKwbR792ViTO3/z6QJmqfgp8WmDcKx7vtwIX+TOGE6KrnzxsZwTGlDvfrdnJqKmLOXo8l3v6NufWc1OIDA+tSjiBEDpPFmfuP3nYzgiMKXfqV4+hRZ04Hr+8Lc2sPlCZCZ1Um9Tr5OFWgwIThzHmhLw85a15m3lg+u9F4qb+qYclgTIWOmcENZKc18q14Kzr7TkCYwJs467DjP5gGfPT9tK7WbwViQug0EgE6fPhs/ud90f3wLyXoeVlVmPImADIyc3j1TmbGPvVWqIjwvjX1e25unNDKw8RQKGRCNLmQF7278O5Wc44SwTGlLl9R7N55fsNnNcigccGtaV21ehAhxTyQiMRZB48eTgs3PofMKYMHc/JZdrCDIZ2aURCXCU+u6s39avHBDos4wqNRLB96cnD9TrY2YAxZWThZqdI3Pqdh2lcM5ZezeItCZQzoZEICj4zUDMlMHEYE0KOHM/h6S/XMGluGvWrxfDmTV3p1cye3ymPvE4EIhIHqKoe9mM8/lHwmQF7hsAYvxvx1gJ+XL+HG3o05q+XtKRKpdA47gxGp/3NiEg7YDJQ0xmUXcANqrrc38H5TMEzAnuq2Bi/OHA0m0qRYURHhjPqwuaMuhC6JNUMdFjmNLx5oOzfwN2q2lhVGwH3ABP8G5aP2RmBMX73+fJtXDj2e8Z+tRZwEoAlgeDgTSKIVdVv8wdU9Tsg1m8R+UPBp4jtqWJjfGbnoUxue3sht769iIQqlRjQvn6gQzIl5E2j3UYReRh4yx3+I06/AcEjdTjsWQc/jYfud9hTxcb4yLdrdjJqymKOZefy14tbMOKcJlYkLgh58xu7CUgApgMfAvE4HcoElxaXuq+XBDYOYyqQhtVjaFO/Kp/e2Zs7zmtqSSBIeXNGkKSqd/o9EmNMuZdfJG7VtoP886r2NKsTx7u3dA90WOYMeZMInhWResB/gCmqusLPMRljyqENuw5z/7SlLNi8j3OaJ1iRuArktIlAVc8TkbrAYGCC27n8VFV93O/R+ZJqoCMwJihl5+YxYfZGxn29jpjIcJ7+Qweu6tTAisRVIF416KnqdlV9HrgVWAw84s+g/Mv+eI0piQPHspkweyMXtqrNrLvPsUqhFZA3D5S1AoYAVwN7gCk4zxIYYyqozOxc/rMgneu6NSa+SiU+H9WbetWsPlBF5c01gonAe8BFbh/DxpgK7Je0vdw/bSkbdx8hOb4KvZrFWxKo4Ly5RmC3BBgTAg4fz+Gpz1cz+afNNKwRw1s3W5G4UFFkIhCR91V1sIgsAzyvtApO8bn2fo/OGFNmRkxewE8b93Dj2Unce1ELYq1IXMgo7jd9l/vavywC8bs1n/3+mmyd0hgDsP9oFpUiwomJCueei5oDQufGNQIdliljRd41pKrb3Le3q+pmzx/g9rIJz0cWTIJ5Lzrv573oDBsT4j5dto0Ln/2e59wicZ0b17QkEKK8uX20byHjLvV1IH616uPih40JITsPZvKntxZw+zuLqFcthkEdGwQ6JBNgxV0juA3nyL+JiHj29RgH/OjvwHyq1SDY8M3Jw8aEoG9W72DUlMUcz8lj9KUt+Z9eyURYfaCQV9w1gneBz4B/AKM9xh9S1b1+jcrXUofD7rVOs1CPkVZ91ISsRjUr0yGxOn8b2IYmCVUCHY4pJ4o7FFBVTQPuAA55/CAiwdfbRH7V0RbB1aplzJnIzVPe+GET901bAkDT2nG8dXM3SwLmJKc7I+gPLMS5fdTzmXIFmvgxLmPMGVq34xD3f7CURVv2c14LKxJnilZkIlDV/u5rctmF40dWdM6EiKycPP79/QZe+GY9sZXCeW5IRwZ1rG/1gUyRTnuVSETOFpFY9/0fReRZEWnkzcJF5BIRWSMi60VkdBHznCsii0VkhYh8X7LwS8P+M5iK7WBmNq//uImL2tRh1t19uPwsqxRqiufN7QIvA0dFpANwH7CZ37utLJKIhAMv4txq2hoYKiKtC8xTHXgJGKiqbYA/lCh6YwzgFIl7c24aeXlKfJVKfDHqHMZf24n4KpUCHZoJAt4kghxVVWAQME5Vx+HcQno6XYH1qrpRVbNwqpYWvG/zWmC6qm4BUNWd3odujAH4eeMeLh03h0c/WcFPG/cAUKdqdICjMsHEm0RwSEQeAK4H/use6Ud68bkGQLrHcIY7zlNzoIaIfCciC0VkWGELEpERIrJARBbs2rXLi1UbU/Edyszmfz9axpAJ88jJy+Od/+nG2U2tSJwpOW+qSg3BOXK/SVW3u9cH/uXF5wprlCx4xTYC6AxcAMQAP4nIPFVde9KHVCcAEwBSU1Ptqq8xwIjJC5m3aQ8390rmnouaUznKisSZ0vGmDPV2EXkH6CIi/YH5qjrZi2VnAIkeww2Bgv0ZZAC7VfUIcEREZgMdgLX4nOUPE/z2HskiJtIpEnfvxS0QgU6NrD6QOTPe3DU0GJiPcyF3MPCziFztxbJ/AZqJSLKIRAHXAJ8UmOdjoLeIRIhIZaAbsKokG1BidveECUKqyidLtnLhs98z9kSRuBqWBIxPeHMu+RDQJf9CrogkAF8B04r7kKrmiMhI4AsgHHhDVVeIyK3u9FdUdZWIfA4sBfKA11R1eek3x5iKZ/uBTP73o+V8tWoHHRpW48pOViTO+JY3iSCswN08e/C+0/tPgU8LjHulwPC/8O6agzEh5+tVTpG47Lw8HurXipt6JRMeZme1xre8SQSfi8gXOP0Wg3Px+NNi5jfG+EjjWrF0alyDvw1sQ1J8bKDDMRWUNxeL/yoiVwK9cO4EmqCqH/o9MmNCUG6eMvHHTazadohnBnegae0qvHlT10CHZSq44vojaAY8DaQAy4B7VfW3sgrM56zWkCnn1u44xH3TlrI4fT/nt6xtReJMmSmurf8NYCZwFU4F0hfKJCJ/WfuF85rfd7Ex5URWTh7jvlrHZc/PYcveo4y7piOv35BqScCUmeKahuJU9VX3/RoRWVQWAfnFgknw88vO+7nPQ80U65zGlBsHM7OZNHcT/drV45H+rall9YFMGSsuEUSLyFn8/oRwjOewqgZPYiisz2JLBCaAjmXl8t78LdzQM+lEkbjaVh/IBEhxiWAb8KzH8HaPYQXO91dQPmd9FptyZO6G3Yz+YBlb9h6lRd04zm4ab0nABFRxHdOcV5aB+FXqcNi12mke6nmnnQ2YgDiYmc0/Pl3Ne/O30LhWZd67pTs9UmoFOixjvHqOoGJofpGTCFr0C3QkJkSNmLyA+Zv28qdzmjDqwubERNnFYFM+hE4iyL9raO1n0LhHYGMxIWPP4eNUjoogJiqc+y5pSbgIHRKrBzosY07iVamIoLdgEvzsVrb4cZwzbIwfqSofL/7tpCJxnRrVsCRgyiWvzghEZCBwjjv4varO8F9IfmB3DZkytO3AMf73w+V8vXonHROrc3XnhoEOyZhinTYRiMg/cLqdfMcddaeI9FTVB/wamS9Vji9+2BgfmbVyB3+ZupjcPOXh/q0Z3jPJisSZcs+bM4LLgI6qmgcgIm8CvwLBkwiO7i5+2BgfSY6PJTWpBv83sC2NalUOdDjGeMXbawTVPd5X80Mc/lXwuQF7jsD4SE5uHhNmb+DuqYsBaFq7CpNu7GpJwAQVb84IngB+FZFvcZ4qPodgOhsA53rA8g8gbTY0Od+uDxifWLXtIPd/sJSlGQfo27qOFYkzQavYRCAiYTg9h3UHuuAkgvtVdXsZxOY7CyY5SQBg4zfOsCUDU0rHc3J58dsNvPTteqpXjuTFazvRr11dxLpBNUGq2ESgqnkiMlJV3+fU/oaDh901ZHzocGYOb8/bzMAO9Xm4f2tqxEYFOiRjzog3TUOzROReYCpwJH+kqu71W1S+ZncNmTN0NCuHd3/ewo1nJ1PLLRKXEGdVQk3F4E0iuMl9vcNjnAJNfB+On9hdQ+YM/Lh+N6OnLyV97zFa16tKz6bxlgRMheJNV5XJZRGIX1n1UVMKB45l88R/VzF1QTrJ8bFMHdGdbk2sSJypeLx5oKwycDfQSFVHuF1YtlDVmX6PzldSh8OuVU6ZibNH2fUB45U/vbWAX9L2cWufFEZd2MzuCDIVljdNQxNxuqrs6Q5nAP/B6cYyeDTr6ySClpcFOhJTju06dJzYSuFUjorg/ktaEhEWRruGwffojDEl4c0DZSmq+hSQDaCqx/i91zJjKgRVZfqiDPqO/Z6xs5wicWc1qmFJwIQEb84IskQkBucCMSKSAhz3a1TGlKHf9h/joQ+X8d2aXXRqVJ0hXRIDHZIxZcqbRPAo8DmQKCLvAGcDw/0ZlDFl5csV2/nL1MUoMGZAa67vYUXiTOjx5q6hWSKyCOfpYgHuUlW7/9IENVVFREipXYXuTWoxZmAbEmtafSATmopMBCLSqcCobe5rIxFppKqL/BeWH2igAzDlQU5uHq/O2cSa7Qd57pqzSEmowuvDuwQ6LGMCqrgzgmfc12ggFViCc0bQHvgZ6OXf0PzFTvtD1cqtB7nvgyUs/+0gF7exInHG5CsyEajqeQAiMgUYoarL3OG2wL1lE54xZy4zO5fx36znle83UL1yFC9f14lL29ULdFjGlBveXCxumZ8EAFR1uYh09F9IxvjWkeM5vDt/C4M6NuDh/q2oXtmKxBnjyZvnCFaJyGsicq6I9BGRV4FV3ixcRC4RkTUisl5ERhczXxcRyRWRq70N3JjiHDmew4TZG8jNU2pVqcSsv5zDM4M7WBIwphDenBHcCNwG3OUOzwZePt2HRCQceBHoi/M08i8i8omqrixkvieBL0oQtzFFmr12Fw9MX8bWA8do26AaPVPiqVXFisQZUxRvbh/NBMa6PyXRFVivqhvhxLWGQcDKAvP9GfgAp+Mb/1n3pfO6+r+QaHeJVET7j2bx+H9XMW1hBk0SYvnPn3qQmlQz0GEZU+55U3SuGfAPoDXOHUQAqOrpylA3ANI9hjOAbgWW3QC4AjifYhKBiIwARgA0atTodCGfasEkmP9v5/2PY6FGkhWeq4BGvLWQhZv3ccd5Kfz5fCsSZ4y3vC069yjOGcF5OE1F3tyDWdg8Be/mfw6n68vc4rr5U9UJwASA1NTUkj8RYD2UVVg7D2VSpVIElaMieLBfKyLDhTb1rT6QMSXhzcXiGFX9GhBV3ayqY3CO4E8nA/As2tIQ2FpgnlRgioikAVcDL4nI5V4su2QK9j9g/REEPVXlPwvS6fvsbJ790ikS1zGxuiUBY0rBmzOCTLcT+3UiMhL4Dajtxed+AZqJSLL7mWuAaz1n8Oz0RkQmATNV9SPvQi+B1OGwc6XTPHT2X+xsIMil7z3Kgx8uY8663XRJqsHQbqVoLjTGnOBNIhgFVAbuBB7DORu44XQfUtUcN3F8AYQDb6jqChG51Z3+SmmDLpVmfZ1E0Kp/ma7W+Nbny7dz9/uLEeD/BrXhj90aE2ZF4ow5I97cNfSL+/YwzvUBr6nqp8CnBcYVmgBUdXhJll1iasWGgll+kbjmdapwdtN4Hh3QmoY1rEicMb5QXNG5GRRTqk1VB/olIr+zo8dgkp2bx4TZG1mz/RDPDz2LJglVeHVYaqDDMqZCKe6M4Gn39UqgLvC2OzwUSPNjTMYAsPy3A9w3bSkrtx3ksvb1OJ6TS6UIuyXUGF8rrujc9wAi8piqnuMxaYaIzPZ7ZCZkZWbnMu7rdUyYvZGasVH8+/rOXNymbqDDMqbC8uZicYKINPF4QjgZSPBvWCaUHc3K5f1f0rmqUwMe6teaapUjAx2SMRWat3cNfSciG93hJNynfI3xlcPHc3h73mZu6d2EmrFRzLq7DzVjrUCcMWWh2ETgPj9QDWgGtHRHr1bVIOy83u4aKq++W7OThz5cztYDx+jQsDo9UmpZEjCmDBWbCFQ1T0RGqur7OD2UBT+7aajc2Hcki8f+u5Lpi36jae0qTLu1J50b1wh0WMaEHG+ahmaJyL3AVOBI/khV3eu3qExI+NPbC1m0eR93nt+UO85vancEGRMg3iSCm9zXOzzGKXC66qPGnGLnwUxiK0UQWymCh/q1IjI8jNb1qwY6LGNCmjdPFiefbh5jTscpEpfBY/9dyeDURB7u35oOidUDHZYxBu/6I6gM3A00UtURbv8ELVR1pt+jMxXClj1Okbgf1u+ma3JNrrMiccaUK972R7AQ6OkOZwD/AYIrEVitoYD4fPk2/jJ1CeFhwuOXt+Xaro2sSJwx5Yw3iSBFVYeIyFAAVT0mxfUiU+4FcehBJL9IXIu6VenTPIFHBrSmfvWYQIdljCmENx3TZIlIDO6N+CKSAgThcwSmLGTl5PHC1+u4c8piVJXk+Fheub6zJQFjyjFvzgjGAJ8DiSLyDnA2MNyPMZkgtTRjP/dNW8rq7YcY0KE+Wbl5dkuoMUGguDLU44F3VfVLEVkIdMdpV7lLVXeXVYCm/MvMzmXsrLW8OmcjCXGVeHVYKn1b1wl0WMYYLxV3RrAOeEZE6uE8TPaeqi4uk6hMUDmalcu0hRkM6ZLI6EtbUS3GisQZE0yKvEagquNUtQfQB9gLTBSRVSLyiIg0L7MITbl0KDObl75bT26eUjM2iq/u7sM/rmxvScCYIHTai8WqullVn1TVs3A6n78CWOX3yHzObh/1lW9W7+CisbN5+os1zN/kVBqpYUXijAlap00EIhIpIgPcC8WfAWuBq/wema+t/8p5XR1cjz+UJ3sOH+euKb9y06QFxEVH8MFtPemRUivQYRljzlBxF4v74nRLeRkwH5gCjFDVI0V9ptxaMAl+ec15P+cZqNYIUocHMqKgdNvbi/g1fR+jLmzG7ec2JSrCm7uPjTHlXXEXix8E3gXuDfpKo6s+PnXYEoFXth/IJC7aKRL3cP/WREWE0aJuXKDDMsb4UHEXi89T1VeDPgkAtBpU/LA5hary3vwt9H32e56dtRaAdg2rWRIwpgLy5oGy4Jc6HDZ8BatmQIehdjZwGpv3HGH0B8v4aeMeejSpxbAejQMdkjHGj0IjEaTPh7VfOO+XT4fUmyCxa2BjKqc+XbaNu99fTGRYGP+4sh3XdEkkqEtLGWNOKzQSQdocyM1x3udlO8OWCE6SXySuVb2qnN+yNg/3b029alYfyJhQEBq3fST1hnA354VFOsMGcIrEPffVWka+9+uJInEvXdfZkoAxISQ0EkFiVzhrmPO+50g7G3AtTt/PgBd+4Lmv1hERJmTl5gU6JGNMAIRG01D6fPh1svN+7nhofklIJ4NjWbk8O2sNr/+widpx0bx+QyoXtLIiccaEqtBIBHaN4CSZ2bl8+OtWhnZtxOhLWxIXbfWBjAllfm0aEpFLRGSNiKwXkdGFTL9ORJa6P3NFpINfArFrBBzMzGb8N+vIyc2jRmwUX9/dh79f0c6SgDHGf4lARMKBF4FLgdbAUBFpXWC2TUAfVW0PPAZM8EswiV3hvAed9/3HhtzZwFcrd5x4MOyXtH0AVKtsCcAY4/Bn01BXYL2qbgQQkSnAIGBl/gyqOtdj/nlAQ79FE+9Wzq7b1m+rKG/2HD7OmBkrmbFkKy3rxvHqsFTaN6we6LCMMeWMPxNBAyDdYzgD6FbM/DfjVDc9hYiMAEYANGrUqHTR7HbKJLB9OdTzTwtUeZNfJO7uvs25tU+KFYkzxhTKn4mgsMdRC+0UQETOw0kEvQqbrqoTcJuNUlNTS96xQPp8+PYJ5/3Mv0B8swrbPLTtwDGqRkcSWymCRwY4ReKa17H6QMaYovnzEDEDSPQYbghsLTiTiLQHXgMGqeoev0RS2F1DFUxenvLOz5vp++xsnvnSOftp26CaJQFjzGn584zgF6CZiCQDvwHX4PRwdoKINAKmA9er6lq/RZJ/11BuVoW8a2jT7iOM/mApP2/ay9lNazG8Z1KgQzLGBBG/JQJVzRGRkcAXQDjwhqquEJFb3emvAI8AtYCX3MJmOaqa6vNgErvCWdfDgteh550Vqlnov0udInFREWE8dVV7/pDa0IrEGWNKRFSDqy/f1NRUXbBgQck+lD4fJl3mnBGEV4LhM4M+GeQXiUvbfYSnv1zDw/1bU6dqdKDDMsaUUyKysKgD7dC4jaQCXSM4npPLs1+u4Y53F6GqJMXHMv7aTpYEjDGlFhqJoII8Wbxoyz76P/8Dz3+znuiIcCsSZ4zxidBIBIld4dz8J4ufC7pmoaNZOfzfjJVc9fJcjhzPYeKNXXh2SEcqRYQHOjRjTAUQGkXnAOKbOq9B+GTx8ew8ZizdyvXdG3PfJS2pUil0fm3GGP8LvT1KkNxRc+BYNm/OTeP2c1OoERvFV3f3oVqM1Qcyxvhe6CWCIPDFiu08/NFy9hzJoltyTbo1qWVJwBjjN5YIypFdh44z5pMV/HfZNlrVq8rrN3ShXcNqgQ7LmDKTnZ1NRkYGmZmZgQ4laEVHR9OwYUMiI70/eLREUI7c/s5ClqQf4N6LmvOnPilEhofGtXxj8mVkZBAXF0dSUpI9GFkKqsqePXvIyMggOTnZ689ZIgiw3/Yfo1pMJFUqRfDogDZUigijmdUHMiEqMzPTksAZEBFq1arFrl27SvS50DnkLGdPUOflKZN/SuOiZ7/nWY8icZYETKizJHBmSvP9heAZQeD/yDbsOszoD5byS9o+ejeL58azkwIdkjEmhIXOGUE5MXPpVi4dN4c12w/xr6vbM/mmriTWrBzosIwxLhHhnnvuOTH89NNPM2bMGK8/P2nSJBISEujYsSMdO3Zk2LBhPo/xu+++o3///j5bniWCMpJf3K9dg2pc0qYuX93Thz+kJtppsDHlTKVKlZg+fTq7d+8u9TKGDBnC4sWLWbx4MZMnTz5pWk5OzpmG6HMh2DRUtjKzc3nhm3Vs2HmEl//Yica1Ynl+6FmBDsuYoDDk3z+dMq5/+3pc3yOJY1m5DJ84/5TpV3duyB9SE9l7JIvb3l540rSpf+px2nVGREQwYsQIxo4dy9///veTpm3evJmbbrqJXbt2kZCQwMSJE73qPnfMmDFs3bqVtLQ04uPjeeKJJ7j++us5cuQIAOPHj6dnz5589913PP3008ycOROAkSNHkpqayvDhw/n8888ZNWoU8fHxdOrU6bTrLAk7I/CjhZv3ctnzc3jx2w3EVoqwInHGBIk77riDd955hwMHDpw0fuTIkQwbNoylS5dy3XXXceeddxb6+alTp55oGpo4cSIACxcu5OOPP+bdd9+ldu3azJo1i0WLFjF16tQil5MvMzOTW265hRkzZjBnzhy2b9/umw112RmBHxw5nsO/vljDmz+lUb9aDG/e1JU+zRMCHZYxQae4I/iYqPBip9eMjfLqDKAwVatWZdiwYTz//PPExMScGP/TTz8xffp0AK6//nruu+++Qj8/ZMgQxo8ff2J4zJgxDBw48MSysrOzGTlyJIsXLyY8PJy1a4vvoHH16tUkJyfTrFkzAP74xz8yYcKEUm1bYUIoEZTd7aPZuXl8umwbw7o35q9WJM6YoDRq1Cg6derEjTfeWOQ8JbnGFxsbe+L92LFjqVOnDkuWLCEvL4/oaKc/kYiICPLyfm858HzC2p/XE0OvachPX+b+o1mMnbWWnNw8qleO4qt7+vC3QW0tCRgTpGrWrMngwYN5/fXXT4zr2bMnU6ZMAeCdd96hV69epVr2gQMHqFevHmFhYbz11lvk5uYC0LhxY1auXMnx48c5cOAAX3/9NQAtW7Zk06ZNbNiwAYD33nvvTDbtFKGXCPzgs2XbuPDZ2Yz/dj0LN+8DoGq0FYkzJtjdc889J9099PzzzzNx4kTat2/PW2+9xbhx40q13Ntvv50333yT7t27s3bt2hNnC4mJiQwePJj27dtz3XXXcdZZzo0l0dHRTJgwgcsuu4xevXrRuHHjM984D6HRZzHAyo/h/WFw21yo08Ynsew8mMkjH6/g8xXbaVO/Kk9d3Z429a1InDGltWrVKlq1ahXoMIJeYd9jcX0WW7vFGbjj3UUsyTjA/Ze05JbeyURYkThjTBCyRFBCGfuOUr1yFFUqRTBmYBuiI8NJSagS6LCMMabUQucQ9gybwPLylEk/buKisbN55ss1ALSpX82SgDEm6IXgGUHJ7xpav9MpErdg8z76NE/g5l7e1/k2xpjyLgQTQcl8smQr976/hMqVwnl2cAeuOKuB1QcyxlQolgiKkJenhIUJHRpWo1+7ujx0WWsS4ioFOixjjPG50LlG4KXM7Fz++dlqbn17IapK41qxPHfNWZYEjAkR4eHhdOzYkbZt2zJgwAD2799/YtqKFSs4//zzad68Oc2aNeOxxx7D8xb8zz77jNTUVFq1akXLli259957i1zPoEGD6NHj5BIYw4cPZ9q0aSeNq1Ll9+uQa9eupV+/fjRt2pRWrVoxePBgduzYcYZbbIngJPM37aXfuDm88v0GalSOIjs3uJ6xMCYkpc+HOc84rz4QExPD4sWLWb58OTVr1uTFF18E4NixYwwcOJDRo0ezdu1alixZwty5c3nppZcAWL58OSNHjuTtt99m1apVLF++nCZNmhS6jv3797No0SL279/Ppk2bvIorMzOTyy67jNtuu43169ezatUqbrvtthJ3S1mY0Gka2rPOed2+DOq0PmnS4eM5PPnZat6at5nEmjG8fXM3ejWLD0CQxpgTPhvt/H8tzvGDsGM5aB5IGNRpC5WqFj1/3XZw6T+9DqFHjx4sXboUgHfffZezzz6biy66CIDKlSszfvx4zj33XO644w6eeuopHnroIVq2bAk4dYNuv/32Qpf7wQcfMGDAAOrUqcOUKVN44IEHThvLu+++S48ePRgwYMCJceedd57X21Kc0DgjSJ8P3z/lvJ/x51OOHHJy8/hy5XZuOjuZL0adY0nAmGCRecBJAuC8Zh4ofv4SyM3N5euvv2bgwIGA0yzUuXPnk+ZJSUnh8OHDHDx4kOXLl58yvSjvvfceQ4cOZejQoV7XDSrJ8ksqNM4I0uZAbrbzPjcH0uawr2ZHJv64iTsvaEb1ylF8fc+5ViDOmPLEmyP39Pnw5kDIzYLwKLjqNUjsekarPXbsGB07diQtLY3OnTvTt29fwOllsKg7BktyJ+GOHTtYv349vXr1QkSIiIhg+fLltG3bttDllMVdin49IxCRS0RkjYisF5HRhUwXEXnenb5URHzb7U6+pN4Q7hSB0/AIfsxpRd+x3/PSdxtYtGU/gCUBY4JRYle44RM4/yHn9QyTAPx+jWDz5s1kZWWduEbQpk0bCtY527hxI1WqVCEuLo42bdqwcOHCwhZ5kqlTp7Jv3z6Sk5NJSkoiLS3tREXTWrVqsW/fvhPz7t27l/j4+BPr92b5paKqfvkBwoENQBMgClgCtC4wTz/gM5ynvLoDP59uuZ07d9ZS+eRO1Uer6kdj79DG98/U/s/P0RW/HSjdsowxfrFy5cpAh6CxsbEn3i9atEgTExM1KytLjx49qsnJyTpr1ixVVT169Khedtll+vzzz6uq6pIlSzQlJUXXrFmjqqq5ubn6zDPPnLL87t2769y5c08Mb9y4UVNSUlRVdcaMGXrBBRfo8ePHVVX1mWee0RtvvPHE+lJSUnTmzJknPvvZZ5/p0qVLT1lHYd8jsECL2K/684ygK7BeVTeqahYwBRhUYJ5BwGQ3znlAdRGp5/NI0ufD4ncBuHjfFJ7reZwPb+9J6/rFXFQyxoS8s846iw4dOjBlyhRiYmL4+OOPefzxx2nRogXt2rWjS5cujBw5EoD27dvz3HPPMXToUFq1akXbtm3Ztm3bSctLS0tjy5YtdO/e/cS45ORkqlatys8//0z//v3p3bs3nTt3pmPHjvz44488+eSTgHOmMnPmTF544QWaNWtG69atmTRpErVr1z7j7fRbGWoRuRq4RFX/xx2+HuimqiM95pkJ/FNVf3CHvwbuV9UFBZY1AhgB0KhRo86bN28uWTBznoFvHgfNQyUcOf8h6H3PGWydMcYfrAy1b5S0DLU/zwgKu8JRMOt4Mw+qOkFVU1U1NSGhFH3/JvWG8Eog4Uh4lDNsjDEG8O9dQxlAosdwQ2BrKeY5c/kXlNLmOEnABxeUjDGmovBnIvgFaCYiycBvwDXAtQXm+QQYKSJTgG7AAVXdhj8kdrUEYEwQ0GJu0zSnV5rmfr8lAlXNEZGRwBc4dxC9oaorRORWd/orwKc4dw6tB44CN/orHmNM+RcdHc2ePXuoVauWJYNSUFX27NlDdHR0iT4XOn0WG2PKvezsbDIyMsjMzAx0KEErOjqahg0bEhkZedJ467PYGBMUIiMjSU62jp/KWmjUGjLGGFMkSwTGGBPiLBEYY0yIC7qLxSKyCyjho8UnxAO7fRhOMLBtDg22zaHhTLa5saoW+kRu0CWCMyEiC4q6al5R2TaHBtvm0OCvbbamIWOMCXGWCIwxJsSFWiKYEOgAAsC2OTTYNocGv2xzSF0jMMYYc6pQOyMwxhhTgCUCY4wJcRUyEYjIJSKyRkTWi8joQqaLiDzvTl8qIp0CEacvebHN17nbulRE5opIh0DE6Uun22aP+bqISK7ba15Q82abReRcEVksIitE5PuyjtHXvPjbriYiM0RkibvNQV3FWETeEJGdIrK8iOm+338V1ZlxsP7glLzeADQBooAlQOsC8/QDPsPpIa078HOg4y6Dbe4J1HDfXxoK2+wx3zc4Jc+vDnTcZfB7rg6sBBq5w7UDHXcZbPODwJPu+wRgLxAV6NjPYJvPAToBy4uY7vP9V0U8I+gKrFfVjaqaBUwBBhWYZxAwWR3zgOoiUq+sA/Wh026zqs5V1X3u4Dyc3uCCmTe/Z4A/Ax8AO8syOD/xZpuvBaar6hYAVQ327fZmmxWIE6cDgyo4iSCnbMP0HVWdjbMNRfH5/qsiJoIGQLrHcIY7rqTzBJOSbs/NOEcUwey02ywiDYArgFfKMC5/8ub33ByoISLfichCERlWZtH5hzfbPB5ohdPN7TLgLlXNK5vwAsLn+6+K2B9BYd0aFbxH1pt5gonX2yMi5+Ekgl5+jcj/vNnm54D7VTW3gvR25c02RwCdgQuAGOAnEZmnqmv9HZyfeLPNFwOLgfOBFGCWiMxR1YN+ji1QfL7/qoiJIANI9BhuiHOkUNJ5golX2yMi7YHXgEtVdU8ZxeYv3mxzKjDFTQLxQD8RyVHVj8okQt/z9m97t6oeAY6IyGygAxCsicCbbb4R+Kc6DejrRWQT0BKYXzYhljmf778qYtPQL0AzEUkWkSjgGuCTAvN8Agxzr753Bw6o6rayDtSHTrvNItIImA5cH8RHh55Ou82qmqyqSaqaBEwDbg/iJADe/W1/DPQWkQgRqQx0A1aVcZy+5M02b8E5A0JE6gAtgI1lGmXZ8vn+q8KdEahqjoiMBL7AuePgDVVdISK3utNfwbmDpB+wHjiKc0QRtLzc5keAWsBL7hFyjgZx5UYvt7lC8WabVXWViHwOLAXygNdUtdDbEIOBl7/nx4BJIrIMp9nkflUN2vLUIvIecC4QLyIZwKNAJPhv/2UlJowxJsRVxKYhY4wxJWCJwBhjQpwlAmOMCXGWCIwxJsRZIjDGmBBnicBUGG6F0cUeP0nFzHvYB+v7zq2KuUREfhSRFqVYxqciUt39ud1jfH0RmXamMRrjDbt91FQYInJYVav4et5ilvEdcK+qLhCREUB/VR1YymUlATNVte2ZxGRMadgZgamwRKSKiHwtIotEZJmInFKdVETqichs9wxiuYj0dscPdT+zXESe9GJ1s4Gm7tOe/3I/t0xEhpxmPWkiEg/8E0hxp/9LRJLy69GLyM8i0sYj5u9EpLOI1BSRj9ya9PPcEiLGlFiFe7LYhLQYEVnsvt8E/AG4QlUPujvbeSLyiZ58Gnwt8IWq/l1EwoHKIlIfeBKneNs+4EsRufw05SkG4FS+vBLoiFPfJx74xa33c8p6Cnx+NNBWVTvCiTOEfFOAwcCj4pQbrq+qC0XkBeBXVb1cRM4HJrvrNqZELBGYiuRY/o4UQEQigSdE5ByccgsNgDrAdo/P/AK84c77kaoudneq36nqLnc57+B0FvJRIet8R0SOAWk4fR/cDbynqrnADnF6COtS2HpKsF3vA7NwSg0MBv7jju8FXAWgqt+ISC0RqaaqB0qwbGOsachUaNfh9FjV2U0QO4BozxncTkDOAX4D3hKnfn9JalZfp6odVfVyVU0v6rNFrMcrqvobsMdt+hmCc4ZAEeuyi36mxCwRmIqsGrBTVbPF6YehccEZRKSxO8+rwOs4XQT+DPQRkXi3GWco4G3fv7OBISISLiIJODv/+UWsx9MhIK6Y5U4B7gOqqeoyj3Vd527HuTjlpytqDX7jR9Y0ZCqyd4AZIrIAp+OS1YXMcy7wVxHJBg4Dw1R1m4g8AHyLc9T9qap+7OU6PwR64PStq8B9qrpdRG4ouB7PD6nqHvcW1OU4vce9WGC504BxOJU2840BJorIUpwqlDd4GaMxJ7HbR40xJsRZ05AxxoQ4SwTGGBPiLBEYY0yIs0RgjDEhzhKBMcaEOEsExhgT4iwRGGNMiPt/a1pWBZVTR5UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Genero una predicción de no fraude (clase mayoritaria)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# Predicciones\n",
    "lr_probs = classifier.predict(X_test)\n",
    "\n",
    "# Mantengo las probabilidades para la salida positiva solamente\n",
    "lr_probs = lr_probs[:, 0]\n",
    "\n",
    "# Calculo los score\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# Resumen\n",
    "print('No Fraud: ROC AUC=%.3f' % (ns_auc))\n",
    "print('ROC AUC: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# Curva ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# graficando\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Fraud')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC AUC')\n",
    "pyplot.xlabel('Falso Positivo')\n",
    "pyplot.ylabel('Verdadero Positivo')\n",
    "plt.title('Exactitud de la detección de fraude')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambiando el número de capas y neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando\n",
    "classifier2 = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input y primera capa\n",
    "classifier2.add(keras.layers.Dense(units = 100 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda capa\n",
    "classifier2.add(keras.layers.Dense(units = 60 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tercera capa\n",
    "classifier2.add(keras.layers.Dense(units = 40 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuarta capa\n",
    "classifier2.add(keras.layers.Dense(units = 25 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quinta capa\n",
    "classifier2.add(keras.layers.Dense(units = 15 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sexta capa\n",
    "classifier2.add(keras.layers.Dense(units = 5 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Septima capa\n",
    "classifier2.add(keras.layers.Dense(units = 3 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Octava capa\n",
    "classifier2.add(keras.layers.Dense(units = 2 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "classifier2.add(keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando\n",
    "classifier2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 15)                390       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 11,124\n",
      "Trainable params: 11,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Resumen\n",
    "classifier2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.1777 - accuracy: 0.9982\n",
      "Epoch 2/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 3/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0041 - accuracy: 0.9983\n",
      "Epoch 4/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0041 - accuracy: 0.9983\n",
      "Epoch 5/5\n",
      "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "# Hago fit al conjunto de entrenamiento\n",
    "model2 = classifier2.fit(X_train.values, y_train.values, batch_size = 128, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 552us/step - loss: 0.0043 - accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004327233415096998, 0.9993153214454651]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediciendo\n",
    "y_pred2 = classifier2.predict(X_test)\n",
    "y_pred2 = (y_pred2 > 0.5)\n",
    "score2 = classifier2.evaluate(X_test, y_test)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.81      0.80      0.80        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Fraud: ROC AUC=0.500\n",
      "ROC AUC: ROC AUC=0.954\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Genero una predicción de no fraude (clase mayoritaria)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# Predicciones\n",
    "lr_probs = classifier2.predict(X_test)\n",
    "\n",
    "# Mantengo las probabilidades para la salida positiva solamente\n",
    "lr_probs = lr_probs[:, 0]\n",
    "\n",
    "# Calculo los score\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "\n",
    "# Resumen\n",
    "print('No Fraud: ROC AUC=%.3f' % (ns_auc))\n",
    "print('ROC AUC: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# Curva ROC\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# graficando\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Fraud')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='ROC AUC')\n",
    "pyplot.xlabel('Falso Positivo')\n",
    "pyplot.ylabel('Verdadero Positivo')\n",
    "plt.title('Exactitud de la detección de fraude')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Se puede notar que una red neuronal de una capa de entrada obtiene practicamente el mismo resultado que una regresión logística en cuanto a su indicar f1 de 0.63, mientras que una red neuronal de 8 capas y con una entrada de 100 neuronas es capaz de aumentar este f1 a un valor de 0.80. Definitivamente un red densa de varias capas entrega un mejor resultado que una regresión logística, sin embargo, dependiendo de su aplicación, el costo computacional puede ser una variable importante, y en ese caso la red neuronal densa de varias capas es bastante más costosa que una regresión logística. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66e8c3d35df53721f8c9353177b5088a6fbd7e676c257dd4e4a19039e83366ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('deep': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
